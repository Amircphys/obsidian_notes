
Агенты `LangChain` — это специализированные компоненты в рамках **LangChain**, которые взаимодействуют с реальным миром.  Эти агенты специально разработаны для выполнения четко определенных задач, таких как ответы на вопросы, генерация текста, перевод на другие языки, обобщение текста и пр.
Например, при всех выдающихся результатах LLM в решении различных задач, модель не сможет ответить на такой простой вопрос: "Какой сегодня день недели?" или о каком-то событии, которое произошло месяц назад. Здесь на помощь LLM приходят различные инструменты (tools) взаимодействия с внешним миром, пользоваться которыми ей помогает агент.    
Архитектура агента `LangChain` выглядит следующим образом:
* **Прием ввода**: агент получает вводимые пользователем данные на естественном языке.
* **Обработка с помощью LLM**: агент использует LLM для обработки входных данных и формулирования плана действий.
* **Выполнение плана**: агент выполняет разработанный план действий, который может включать взаимодействие с другими инструментами или службами.
* **Доставка выходных данных**: впоследствии агент доставляет выходные данные выполненного плана обратно пользователю.
Существует 2 типа агентов:
* `Toolkits` агенты (агент - ящик инструментов) - заточенные под выполнение конкретных задач или для работы с конкретным API.
* `Generic` агенты (общего назначения) - универсальные, которые способны выполнять множество метазадач.

Для использования агентов нам понадобятся 3 компонента:
* LLM
* Инструменты (Tools)
* Сами агенты

Теперь давайте создадим наш первый `Tool` - калькулятор, используя уже знакомую нам `LLMMathChain`:
```python
from langchain.chains import LLMMathChain
from langchain.agents import Tool

llm_math = LLMMathChain.from_llm(llm=llm)
# создаём math tool, задаём имя, описание и функцию
math_tool = Tool(
	name='Калькулятор',
	func=llm_math.run,
	description='Может производить математические расчёты.'
)
# Для передачи в агента, нам нужно поместить инструменты в список
tools = [math_tool]
```
Создадим нашего **первого агента**, передав в него инструменты (пока 1)
```python
from langchain.agents import initialize_agent
first_agent = initialize_agent(
	tools=tools,
	llm=llm,
	verbose=True,
	handle_parsing_errors=True,
	max_iterations=3
)
first_agent("Сколько будет (4.5*2.1)+2.2?")
first_agent('''
У Маши было 3 яблока, Гриша принёс ещё 2 с половиной ящика яблок.
Сколько всего яблок у ребят, если ящик вмещает 8 яблок?
''')
```
##### А что будет, если мы спросим не математический вопрос?

```python
first_agent("Столица Хорватии?")
```
Получим ошибку: `ValueError: unknown format from LLM: I'm sorry, but I can only help with math-related questions.`
Это происходит потому, что агент принуждает к использованию инструмента (это не всегда так). Обходной путь, который мы можем реализовать, — это просто добавить еще один инструмент, который может ответить на этот вопрос.
Если мы хотим, чтобы агент мог отвечать на `general knowledge questions` (общие вопросы), можно добавить саму LLM как инструмент `LLM-tool`.
```python
# создаём LLM tool
llm_tool = Tool(
	name='Language Model',
	func=llm.predict,
	description='Отвечает на общие вопросы'
)
# Добавляем его к другим инструментам
tools.append(llm_tool)
first_agent = initialize_agent(
	tools=tools,
	llm=llm,
	verbose=True,
	handle_parsing_errors=True,
	max_iterations=3
)
```
Рассмотрим ещё один способ создания инструмента из Python-функции, при помощи декоратора `tool`.
В функцию обязательно необходимо добавлять описание (`docstring`), чтобы агент понимал для чего её нужно применять!
```python
from langchain.agents import tool
@tool
def get_word_length(word: str) -> int:
	"""Возвращает длину слова""" # добавляем docstring
	return len(word)
tools = [get_word_length]
```
Создадим агента с нашим инструментом, и посмотрим как он справится с задачей:
```python
agent = initialize_agent(
	tools=tools,
	llm=llm,
	verbose=True,
)
agent("Сколько букв в слове зачёт?")
```
Если вы видели такие инструменты кодирования, как `GitHub Copilot`, и задавались вопросом, как они работают, то одна из задач, которые они делают, — это заставляют языковую модель написать код, а затем выполнить этот код. Мы можем сделать то же самое, создав агент `Python`. Для этого мы используем LLM, а также инструмент(tool) `PythonREPL`, который представляет собой способ выполнения`Python` кода, немного похожий на `Jupyter Notebook`, поэтому агент может выполнить этот код, используя его, получить некоторые результаты, и эти результаты будут переданы обратно агенту, чтобы он мог решить, что делать дальше.
```python
from langchain_experimental.tools.python.tool import PythonREPLTool
from langchain.agents import initialize_agent 

py_agent = initialize_agent(
	tools=[PythonREPLTool()],
	llm=llm,
	verbose=True,
	handle_parsing_errors=True,
	max_iterations=3
)
names = ["Борис", "Олег", "Ия", "Александр", "Зоя"]
py_agent.run(f'Отсортируй имена в списке по длине в порядке убывания и покажи результат: {names}')
```

#### Создаём первый мини-сервис
Теперь давайте попробуем реализовать "полезного" агента с использованием нескольких инструментов.

В этом примере мы будем использовать инструменты `Wikipedia`, `DuckDuckGo` и `Arxiv`, чтобы создать простой агент для написания эссе. <br> [Здесь](https://python.langchain.com/docs/integrations/tools/) доступен длинный список инструментов, которые агенты могут использовать для взаимодействия с внешним миром.

```python
from langchain.agents import load_tools
from langchain.tools import DuckDuckGoSearchRun
search = DuckDuckGoSearchRun()
# инструменты, поддерживаемые LangChain "из коробки", можно подгружать функцией load_tools
tools = load_tools(["arxiv", "wikipedia"], llm=llm)
tools.extend([
	Tool(
	name="Search",
	func=search.run,
	description="useful for when you need to answer questions about current events."
	),
])

essay_agent = initialize_agent(
	tools,
	llm,
	verbose=True,
	handle_parsing_errors=True,
	max_iterations=5)

prompt = "Write a 1000-word essay on topic: {topic}, use the tools to retrieve the necessary information."
topic = "Style Quentin Tarantino in cinema"
print(essay_agent.run(prompt.format(topic=topic)))
```
Агент, в целом, справился с задачей, видно, что сначала он сходил в Википедию, затем в Arxiv, потом выдал требуемое эссэ.

Но в `Final answer` вместо эссэ на 1000 слов агент записал краткий ответ на вопрос, видимо, нужно получше составить промпт (можете потюнить промпт в качестве самостоятельной работы).

Тут мог возникнуть справедливый вопрос: А зачем использовать агента, если можно сделать тоже самое, например, с помощью `RouterChain`?

В отличии от цепочек, где порядок действий жёстко прописан, агент получает на вход запрос (промпт), список доступных инструментов и сам решает какие именно инструменты и в каком порядке применить для решения задачи.

Так же с помощью `load_tools` можно подгрузить такой интересный tool:

```python
tools = load_tools(["human"])
```
В документации к этому tool сказано:

> Human are AGI so they can certainly be used as a tool to help out AI agent when it is confused.
> 
[Здесь](https://python.langchain.com/docs/integrations/tools/human_tools) можно прочитать про этот инструмент подробнее

Подводя итог, можем выделить несколько явных преимуществ которые дают агенты `LangChain`:
* **Удобство для пользователя**: агенты `LangChain` специально разработаны так, чтобы быть понятными и доступными даже для разработчиков, у которых нет большого опыта работы со сложными языковыми моделями.
* **Универсальность**: адаптируемость агентов `LangChain` позволяет им находить применение для самых разных сценариев и требований.
* **Расширенные возможности.** Используя возможности языковых моделей, агенты LangChain предоставляют такие функции, как понимание и генерация естественного языка, давая доступ к большому количеству функций.