Виды тестирования
	○ Unit-тесты (модульные тесты)
	○ Функциональное тестирование
	○ Системное тестирование
	○ Интеграционное тестирование
	○ Регрессионное тестирование
	○ Тестирование производительности
	 - Нагрузочное
	 - Стресс

**TDD (Test Driven Development)** – техника разработки ПО, основывается на
повторении коротких циклов разработки: пишется тест, покрывающий
желаемое изменение, затем пишется код, который позволит пройти тест, и
далее проводится рефакторинг нового кода.

**TDD: алгоритм**
	1. Пишется тест на функцию/класс
	2. Проверяется, что тесты упали (кода еще нет)
	3. Пишется код функции/класса для прохождения тестов
	4. Проверяется прохождение тестов
	5. На этом шаге можно задуматься о качестве кода, провести рефакторинг
	6. Прогоняются тесты

**Степень покрытия тестами**
	`overage` - библиотека для проверки покрытия тестами.
	`pip install coverage`
	`coverage run tests.py`
	`coverage report -m`
	`coverage html`

**Инструменты тестирования в Python**
	○ doctest
	○ unittest
	○ pytest
	○ factory_boy
	○ selenium


Примеры кода:

```
@pytest.mark.parametrize(
	("number", "expected"),    
	[        
		pytest.param(0, 1, id="return one if number equal zero"),        
		(1, 1),        
		pytest.param(5, 120, marks=pytest.mark.skip(reason="Slow test")),    
	],
)
def test_factorial(number: int, expected: int) -> None:    
	actual = function(number)        
	assert expected == actual




@pytest.mark.skip( 
		reason="Известная ошибка в версии библиотеки 1.2.3, исправление ожидается в следующем релизе",
)
def test_some_function() -> None:    
	assert some_function() == expected_result
```


```
@pytest.mark.skipif(    
	sys.platform == "win32",     
	reason="Тест не поддерживается на Windows",
)
def test_unix_specific_function() -> None:    
	assert unix_specific_function() == expected_result
```

 **pytest.mark.xfail** - помеченные им тесты должны завершаться неперехваченной ошибкой. В моей практике встречались тесты, которые были завязаны на удалённую базу данных(не являюсь ценителем таких тестов). В один прекрасный момент в удалённой тестовой БД поменялись данные, и нам нужно было ждать накатки свежих, корректных данных. Как раз тогда мы и использовали данную маркировку, чтобы не удалять требуемый тест и иметь возможность выпускать новые версии приложения:
```
@pytest.mark.xfail(    
	reason="Нужно дождаться, пока накатят новые акционные "           
			"цены после НГ(неделя максимум думаю).",
)
class TestDomainPrices:  
	...
```

Одна из самых важных фич **pytest** это, конечно же, фикстуры(**pytest.fixture**)
Фикстуры (fixtures) в **pytest** — это мощный механизм для подготовки данных, ресурсов или состояний, которые требуются для выполнения тестов. Они позволяют инкапсулировать логику инициализации и очистки, делая тесты чище и поддерживаемыми. Фикстуры объявляются через декоратор `@pytest.fixture` и могут передаваться в тестовые функции как параметры.
![[Pasted image 20250408173137.png]]
![[Pasted image 20250408173221.png]]
![[Pasted image 20250408173256.png]]
![[Pasted image 20250408173332.png]]
![[Pasted image 20250408173430.png]]

### **Итог**

1. **Фикстура** — это функция с декоратором `@pytest.fixture`, которая подготавливает данные для тестов.
    
2. **Как использовать:**    
    - Создай фикстуру (например, `def my_data()`).
    - Передай ее как параметр в тест (например, `def test_example(my_data)`).
        
3. **Зачем:**
    - Чтобы не дублировать код подготовки данных.
    - Чтобы автоматически чистить ресурсы (как удаление файла в примере 2).
    - Чтобы легко переиспользовать одни и те же данные в разных тестах.