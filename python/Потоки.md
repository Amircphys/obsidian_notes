### Конспект занятия: Потоки, процессы, IPC и subprocess в Python

---

#### **1. Потоки и GIL (Global Interpreter Lock)**
**Поток (Thread)** — это "виртуальный" процесс внутри программы, который может выполнять задачи параллельно с другими потоками. 
**Thread (поток)** - это сущность операционной системы, процесс
выполнения на процессоре набора инструкций, а именно программного кода.
Поток — это отдельное направление выполнения внутри процесса. Каждый процесс содержит хотя бы один поток (главный поток). В Python с помощью `threading` можно создавать дополнительные потоки.

В Python для работы с потоками используется модуль `threading`. Модуль `threading` в Python используется для создания и управления потоками (потоками выполнения) в рамках одного процесса. Это позволяет запускать несколько операций одновременно, что полезно для задач, требующих параллельного выполнения, например, в многозадачности, когда нужно не блокировать основной поток выполнения.
##### **Методы класса `Thread`:**

| Метод / атрибут       | Описание                                                                                    |
| --------------------- | ------------------------------------------------------------------------------------------- |
| `.start()`            | Запускает поток.                                                                            |
| `.run()`              | Код, который выполняется в потоке (обычно не вызывается напрямую).                          |
| `.join(timeout=None)` | Ожидает завершения потока. `timeout` — максимальное время ожидания.                         |
| `.is_alive()`         | Проверяет, жив (работает) поток или уже завершился.                                         |
| `.name`               | Имя потока. Можно изменить при создании или в процессе.                                     |
| `.ident`              | Идентификатор потока (получается после старта).                                             |
| `.daemon`             | Флаг, определяющий, является ли поток демоном. Демон-потоки не мешают завершению программы. |
#### Параметры конструктора `Thread`

- `target`: callable, функция, которую нужно выполнить.
- `args`: кортеж аргументов для `target`.
- `kwargs`: словарь именованных аргументов для `target`.
- `daemon`: булево значение, определяющее, является ли поток демоном.
- `name`: имя потока.

```python
import threading
import time

def task(name):
    print(f"Задача {name} началась")
    time.sleep(2)  # Имитация долгой операции (I/O-bound)
    print(f"Задача {name} завершилась")

# Создаем два потока
thread1 = threading.Thread(target=task, args=("A",))
thread2 = threading.Thread(target=task, args=("B",))

# Запускаем потоки
thread1.start()
thread2.start()

# Ждем завершения работы потоков
thread1.join()
thread2.join()

print("Все потоки завершены")
```

## Демон-потоки

Если поток отмечен как `daemon=True`, то интерпретатор не будет ждать его завершения при выходе из программы.

```python
t = threading.Thread(target=worker, daemon=True)
t.start()
```

**GIL** — механизм в Python, который не позволяет нескольким потокам выполнять Python-код одновременно (мешает истинной многопоточности для CPU-bound задач).
##### **Почему GIL глобальный?**
- **GIL (Global Interpreter Lock)** — это мьютекс, который предотвращает выполнение Python-кода одновременно в нескольких потоках.
- **Причина:** Внутренняя структура CPython (основной реализации Python) не потокобезопасна. GIL упрощает работу с памятью.
- **Последствия:** 
  - Потоки эффективны только для I/O-bound задач (ожидание ввода/вывода).
  - Для CPU-bound задач (вычисления) используйте процессы.

**Когда использовать потоки:**  
- Для I/O-bound задач (ожидание данных из сети, чтение файлов).  
- Не подходят для CPU-bound задач (математические вычисления).


## Что такое синхронизация потоков?

Синхронизация потоков — это набор механизмов и техник, которые позволяют нескольким потокам **безопасно** совместно использовать ресурсы (переменные, файлы, устройства) без возникновения ошибок из-за одновременного доступа.

### Почему нужна синхронизация?

В параллельном или конкурентном исполнении несколько потоков могут одновременно обращаться к одним и тем же данным. Без контроля такой доступ приводит к состояниям гонки (*race conditions*), когда итоговое значение переменной зависит от непредсказуемого порядка операций потоков, что вызывает неправильное поведение программы.

## Когда возникает необходимость в синхронизации

- Когда несколько потоков читают и/или записывают в **одну и ту же общую переменную**
- Когда надо обеспечить выполнение части кода **атомарно** (неделимо)
- При работе с общими ресурсами (файлы, сетевые соединения, базы данных)
- Для координции последовательнотсти действий потоков (например, один поток должен ждать, пока другой завершит определенную операцию)

## Основные механизмы синхронизации в Python (модуль `threading`)

1. **Lock (Мьютекс)**  
   Простейший механизм блокировки. Обеспечивает взаимоисключение. Только один поток одновременно может захватить `Lock`, остальные ждут, пока он будет освобожден.
	```python
'''
Тут создается 100 потоков и в каждом потоке значение increment увеличивается на 1
Через lock только в одном потоке значение глобально переменной увеличивается на 1, остальные потоки ждут пока lock освободится
'''
lock = threading.Lock()
counter = 0

def increment():
    global counter
    with lock:  # Автоматически захватывает и освобождает блокировку
        counter += 1

threads = []
for _ in range(100):
    thread = threading.Thread(target=increment)
    threads.append(thread)
    thread.start()

for t in threads:
    t.join()

print("Counter:", counter)  # Всегда 100

### Еще пример
counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100000):
        with lock:
            counter += 1

threads = [threading.Thread(target=increment) for _ in range(5)]

for t in threads:
    t.start()
for t in threads:
    t.join()

print(counter)  # Ожидаем 500000, Без блокировки результат, скорее всего, будет меньше 500000 из-за условий гонки.
```
	**Важные советы**
	
	- Не забывай всегда освобождать блокировки, иначе возникнет **deadlock** (взаимная блокировка), когда потоки ждут друг друга бесконечно.
	- Используй менеджеры контекста (`with lock:`), чтобы автоматически высвобождать ресурс.
	- Минимизируй код внутри критической секции, чтобы не блокировать ресурсы долго.
	- Если задача требует сложной синхронизации, подумай о `Condition` или `Event`.
	- Для очередей и обмена данными между потоками удобно использовать потокобезопасный модуль `queue`.

2. **Semaphore (Семафор)**  
   Позволяет ограничить число потоков, одновременно работающих в какой-то секции (например, максимум N потоков).  
   Используется для ограничения общего доступа к какому-то ресурсу с ограниченной вместимостью. 
	```python
semaphore = threading.Semaphore(3)  # Одновременно могут работать 3 потока

def task():
    with semaphore:
        print("Поток начал работу")
        time.sleep(2)
        print("Поток завершил работу")

for _ in range(5):
    threading.Thread(target=task).start()
>>> Поток начал работу 
>>> Поток начал работу 
>>> Поток начал работу
>>> Поток завершил работу 
>>> Поток начал работу 
>>> Поток завершил работу 
>>> Поток начал работу 
>>> Поток завершил работу 
>>> Поток завершил работу 
>>> Поток завершил работу
```
3.  **Event (Событие)**  
   Позволяет одному потоку оповестить другие потоки о наступлении какого-то события (через метод `.set()`), которые могут ждать события с помощью `.wait()`.
```python
event = threading.Event()

def waiter():
    print("Ожидаем событие...")
    event.wait()  # Блокируется, пока событие не будет установлено
    print("Событие произошло!")

def setter():
    time.sleep(3)
    print(f"Сигнализируем о наступлении события")
    event.set()  # Сигнализирует о наступлении события

threading.Thread(target=waiter).start()
threading.Thread(target=setter).start()
>>> Ожидаем событие...
>>> Сигнализируем о наступлении события 
>>> Событие произошло!
```
4. **Barrier (Барьер)**  
   Позволяет синхронизировать определённое количество потоков, остановив каждый поток до тех пор, пока все потоки не достигнут барьера.
5.  **RLock (Рекурсивный Lock)**  
    Позволяет одному и тому же потоку многократно захватывать одну и ту же блокировку без взаимной блокировки на самом себе (рекурсия в захвате блокировки).
6. **Condition (Условие)**  
   Более продвинутый механизм. Позволяет потокам ждать определённого условия и сигнализировать друг другу, что условие наступило. Используется совместно с `Lock` или `RLock`.
7. **Timer**
	Это подкласс `Thread`, который создаёт поток, в котором через указанное количество секунд вызывается заданная функция. Это удобно, если нужно выполнить какую-то задачу с задержкой, не блокируя основной поток исполнения.
	```python
	threading.Timer(interval, function, args=None, kwargs=None)
	```
	
	- `interval` — время в секундах, через которое будет вызвана функция.
	- `function` — функция, которую нужно выполнить.
	- `args` — кортеж позиционных аргументов для функции (по умолчанию пустой).
	- `kwargs` — словарь именованных аргументов для функции.
	
	```python
	def greet(name, greeting="Hello"):
	    print(f"{greeting}, {name}!")
	
	timer = threading.Timer(3, greet, args=("Alice",), kwargs={"greeting": "Hi"})
	timer.start() # Через 3 секунды выведет: `Hi, Alice!`
```
	**Основные методы**
	
	- `start()` — запускает таймер и отсчёт времени.
	- `cancel()` — отменяет выполнение таймера (если он ещё не сработал).
	
	**Особенности**
	
	- Таймер запускается в отдельном потоке, поэтому функция выполняется параллельно с основным потоком.
	- Если программа завершится до срабатывания таймера, функция может не выполниться.
	- Можно использовать для периодических задач, но для периодического повторения удобнее использовать другие механизмы, например, цикл с сном или `sched.scheduler`.


**Локальные данные потоков (`threading.local`)**
Каждый поток может иметь свои уникальные данные, которые не видны другим потокам.
```python
local_data = threading.local()

def task():
    local_data.value = threading.get_ident()  # ID потока
    print(f"Локальное значение: {local_data.value}")

threads = []
for _ in range(3):
    t = threading.Thread(target=task)
    threads.append(t)
    t.start()

for t in threads:
    t.join()
>>> Локальное значение: 128705372358208 
>>> Локальное значение: 128705372358208 
>>> Локальное значение: 128705372358208
```
---
![[Pasted image 20250419211654.png]]

### **2. Процессы**
Модуль `multiprocessing` в Python — это про процессы, не потоки!
В Python есть несколько способов параллелить вычисления:
- Потоки (threads) — `threading`
- Процессы — `multiprocessing`

**Главное отличие процессов от потоков:** процессы запускаются в отдельных адресных пространствах, каждый процесс — это независимая копия интерпретатора Python. Из-за GIL (Global Interpreter Lock) в CPython параллельные потоки не делают настоящий параллелизм для CPU-bound задач, а процессы могут.
#### Зачем нужны процессы?
- Чтобы полностью использовать несколько ядер CPU
- Чтобы избежать ограничений GIL
- Для изоляции вычислений — сбой в одном процессе не "убьёт" программу целиком
#### Как запустить процесс через `multiprocessing`
Самое простое — функция, которую надо выполнить — и создаём процесс с этой функцией.
```python
from multiprocessing import Process
import os

def worker(number):
	print(f'Процесс {os.getpid()} получил число: {number}')

if __name__ == '__main__':
	p = Process(target=worker, args=(42,))
	p.start() # Запускаем процесс
	p.join() # Ждём, пока он завершится

```

- `target` — функция, которую запускаем
- `args` — аргументы для функции
- `start()` — стартуем процесс
- `join()` — ждём завершения процесса (необязательно, но обычно нужно)
---
## Несколько процессов

Реализация параллельной обработки
```python
from multiprocessing import Process
def worker(num):
	print(f'Process {num} started')

if __name__ == '__main__':
	processes = []
	for i in range(4):
		p = Process(target=worker, args=(i,))
		p.start()
		processes.append(p)
	for p in processes:
		p.join()
	
	print('Все процессы завершены')
>>> Process 0 started 
>>> Process 1 started 
>>> Process 2 started 
>>> Process 3 started 
>>> Все процессы завершены
```

#### Возвращаем результат из процесса?
Процессы — независимы. Они не общаются напрямую. Чтобы получить данные из процесса, используют:
- Очереди (`multiprocessing.Queue`)
- Общая память (`Value`, `Array`)
- Менеджер (`multiprocessing.Manager`)

```python
from multiprocessing import Process, Queue
def worker(q, n):
	q.put(n * n) # Кладём в очередь квадрат числа

if __name__ == '__main__':
	q = Queue()
	p = Process(target=worker, args=(q, 7))
	p.start()
	p.join()
	result = q.get()
	print(f'Квадрат: {result}') # Квадрат: 49

```
#### Пул процессов: удобный способ запускать много задач
Если у тебя много мелких задач — не создавай процесс на каждую, а используй пул.

```python

from multiprocessing import Pool
def square(n):
	return n * n

if __name__ == '__main__':
	with Pool(4) as pool:
	results = pool.map(square, [1, 2, 3, 4, 5])
	print(results) # [1, 4, 9, 16, 25]

```
- `Pool(4)` — пул из 4 процессов
- `map` — запускает функцию для каждого элемента списка параллельно и возвращает результаты в том же порядке

## Важные моменты:

- На Windows обязательно проверять код через `if __name__ == '__main__'`, чтобы не было рекурсивного запуска процессов.
- Не передавай в процессы слишком большие объекты — передаются они через pickle, что влияет на производительность.
- Если хочешь обмениваться данными — лучше использовать очереди или менеджеры.

---
### Введение в многопроцессность в Python
В Python для запуска нескольких процессов и организации их совместной работы есть модуль `multiprocessing`. Он позволяет создавать отдельные процессы — отдельные программы внутри вашей программы, которые работают параллельно.
Отличие от потоков (`threading`) — в Python есть GIL (Global Interpreter Lock), который ограничивает выполнение потоков в одном процессе, из-за чего потоки эффективны для ввода-вывода, но не для CPU-bound задач.
Процессы же имеют отдельную память, и могут выполняться параллельно на нескольких ядрах. Но у них сложнее организовать обмен данными и синхронизацию, так как память не общая.
##### Основные идеи
- **Процесс (Process)** — отдельная копия программы.
- **Обмен данными** — процессы не разделяют память, поэтому нужно использовать специальные механизмы.
- **Синхронизация** — нужно контролировать одновременный доступ к общим ресурсам, чтобы не получить ошибки.

# Пример 2: Обмен данными через **Queue**

Память процессов изолирована, поэтому нельзя просто так передать данные. `multiprocessing` предоставляет объекты для обмена данными:

- **Queue** — очередь, в которую процессы могут помещать и из которой выбирать данные.
- **Pipe** — двунаправленный канал связи.
- **Shared Memory** — объекты с памятью, которую можно разделить.
Сначала рассмотрим `Queue` — наиболее простой способ обмена сообщениями.

```python
from multiprocessing import Process, Queue
def sender(q):
	for i in range(5):
	print(f"Отправляем: {i}")
	q.put(i) # помещаем данные в очередь

def receiver(q):
	while True:
		item = q.get() # забираем данные из очереди
		print(f"Получили: {item}")
		if item == 4:
			break

if __name__ == '__main__':
	q = Queue()

	p1 = Process(target=sender, args=(q,))
	p2 = Process(target=receiver, args=(q,))
	
	p1.start()
	p2.start()
	
	p1.join()
	p2.join()
```

**Объяснение:**

- `Queue` — потокобезопасная очередь для обмена данными между процессами.
- `sender` кладет в очередь числа 0,1,2,3,4.
- `receiver` читает из очереди, пока не увидит число 4.
- Так процессы обмениваются данными.

#### Пример 2: Синхронизация с Lock (блокировка)

Когда несколько процессов работают с общими ресурсами (например, записывают в файл, изменяют общий счетчик), важно не допустить одновременного доступа — чтобы не возникло ошибок.

Для этого используется `Lock`.

Пример: несколько процессов увеличивают общую переменную.
Но дети с процессами нельзя просто так делить переменные, поэтому создадим разделяемую память на примере `Value`.

```python
from multiprocessing import Process, Value, Lock
import time

def increment(counter, lock):
	for _ in range(100):
	time.sleep(0.01) # имитируем работу
	with lock:
		counter.value += 1 # изменяем общую переменную с блокировкой

if __name__ == '__main__':
	counter = Value('i', 0) # целочисленная общая переменная
	lock = Lock() # объект блокировки
	processes = []
	for _ in range(5):
		p = Process(target=increment, args=(counter, lock))
		p.start()
		processes.append(p)
		
	for p in processes:
	p.join()

	print(f"Итоговое значение счетчика: {counter.value}")

```

**Объяснение:**
- `Value` — это прокси для переменной, которая хранится в общей памяти, доступной для всех процессов.
- `Lock` гарантирует, что только один процесс в момент времени может изменять значение `counter`.
- Благодаря блокировке мы избегаем гонок данных (race conditions).
- 5 процессов по 100 инкрементов → итог должен быть 500.

#### Пример 3: Обмен комплексными структурами через Manager

Если нужно, чтобы несколько процессов совместно использовали сложные объекты (списки, словари), используем `Manager`.

```python
from multiprocessing import Process, Manager
def worker(shared_list, idx):
	shared_list.append(f"данные из процесса {idx}")
  
if __name__ == '__main__':
	manager = Manager()
	shared_list = manager.list() # создаём разделяемый список
	processes = []
	for i in range(3):
		p = Process(target=worker, args=(shared_list, i))
		p.start()
		processes.append(p)

	for p in processes:
		p.join()
	print(f"Общий список: {shared_list}")
	>>> Общий список: ['данные из процесса 0', 'данные из процесса 1', 'данные из процесса 2']

```

**Объяснение:**
- `Manager` создаёт сервер, через который процессы могут совместно работать с объектами.
- `manager.list()` — разделяемый список.
- Процессы добавляют в него свои данные.
- В конце узнаём, что добавлено.

#### Подводим итог — полезные объекты для синхронизации и обмена:


| Объект                              | Задача                                                | Особенности                            |
| ----------------------------------- | ----------------------------------------------------- | -------------------------------------- |
| `Queue`                             | Обмен данными по очереди                              | FIFO, блокирующий режим                |
| Pipe                                | Двунаправленная связь между двумя процессами          | Быстрее очереди, но только 2 участника |
| Value                               | Общая (поделённая) переменная                         | Только примитивные типы                |
| Array                               | Общий массив                                          | Также для простых типов                |
| Manager                             | Менеджер для сложных объектов (списки, словари и др.) | Медленнее чем Value, но гибко          |
| Lock                                | Мьютекс для синхронизации                             | Блокирует доступ к ресурсу             |
| `RLock`, `Semaphore`, `Event` и др. | \| `RLock`, `Semaphore`, `Event` и др. \|             | Используются в продвинутых случаях     |

### **c. Разделяемая память (`Value`, `Array`):**
```python
from multiprocessing import Process, Value, Array

def task(n, arr):
    n.value = 42
    arr[0] = 100

if __name__ == "__main__":
    num = Value("i", 0)
    arr = Array("i", [1, 2, 3])
    
    p = Process(target=task, args=(num, arr))
    p.start()
    p.join()
    
    print(num.value)  # 42
    print(arr[:])     # [100, 2, 3]
```

### **d. Сокеты:**
```python
# Сервер
import socket

s = socket.socket()
s.bind(("localhost", 5000))
s.listen()
conn, addr = s.accept()
print(conn.recv(1024).decode())  # Привет от клиента!
conn.close()

# Клиент
s = socket.socket()
s.connect(("localhost", 5000))
s.send("Привет от клиента!".encode())
s.close()
```

### **e. Сигналы:**
Процессы могут отправлять сигналы (например, `SIGINT` для прерывания).
```python
import signal
import os

def handler(signum, frame):
    print("Получен сигнал:", signum)

signal.signal(signal.SIGUSR1, handler)
print("PID процесса:", os.getpid())  # Передать этот PID другому процессу для отправки сигнала
```

---

## Итоговая таблица: Потоки vs Процессы

| **Критерий**      | **Потоки**                          | **Процессы**                       |
|-------------------|-------------------------------------|------------------------------------|
| Память            | Общая                               | Раздельная                         |
| GIL               | Есть (нет параллелизма для CPU)     | Нет (истинная параллельность)      |
| IPC               | Не требуется                        | Очереди, сокеты, сигналы           |
| Сложность         | Проще                               | Сложнее                            |
| Использование     | I/O-bound задачи                    | CPU-bound задачи                   | 

---

### Примеры задач:
- **Потоки:** Веб-сервер (обработка множества запросов), чтение/запись файлов.
- **Процессы:** Обработка изображений, машинное обучение, сложные вычисления.