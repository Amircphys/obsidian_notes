
Один из ведущих исследователей причинно-следственных связей, [Джуда Перл](http://bayes.cs.ucla.edu/jp_home.html), в своих работах предложил так называемую лестницу причинности. Данные нам нужны для того, чтобы делать на их основе какие-то выводы, и мы можем делать три качественно разных вида выводов.

**Первое - это ассоциации, то есть какие-то события происходят вместе.** Например, у нас есть данные, мокрая трава или нет, и есть разметка, прошел дождь или нет. Почти всегда, когда дождь прошел, трава мокрая. Это ассоциация, и тут есть проблема: [после не значит вследствие](https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B0), [correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation). То есть если мы видим, что трава мокрая, вовсе не обязательно, что был дождь - просто могла проехать поливальная машина или кто-то разлил воду.

Хороший пример - когда началась эпидемия ковида, люди, которых клали под аппарат искусственной вентиляции легких, умирали чаще тех, кого не положили. И возникла такая городская легенда, что аппараты искусственной вентиляции легких убивают, сопротивляйтесь, если вас будут пытаться класть под ИВЛ.

На самом-то деле, просто под ИВЛ, поскольку их тогда не хватало, клали тех, кто был в самом тяжелом состоянии, и они, к сожалению, чаще других умирали. Но их убивал не аппарат искусственной вентиляции легких, их убивала все-таки пневмония. И первый этап работы с данными, первый уровень - это ассоциация, то, что встречается вместе. В статистике это описательная, или дескриптивная статистика.

**Второй уровень работы с данными - это эксперимент.** Мы смотрим на наши данные, делаем какие-то предположения о зависимости и говорим, ну, мы можем сделать вот это и добиться такого-то результата. Например, у человека болит голова, он решает съесть таблетку, голова перестает болеть. Это эксперимент. Но у нас тут не вся правда. Перестала ли бы у него болеть голова, если бы он не съел таблетку - мы не знаем. Потому что для этого нам надо было бы иметь две параллельных реальности и два человека - один съел таблетку, другой не съел. **Для того, чтобы однозначно проанализировать, было то или иное действие причиной, нам нужно две параллельных реальности, а лучше много - для того, чтобы добиться статистической значимости. А у нас нет параллельных реальностей, это фундаментальная проблема причинно-следственного анализа.** 


 Сначала у нас стало не хватать врачей на разметку медицинских данных, а просто в какую-нибудь краудсорсинговую платформу вроде [Amazon Mechanical Turk](https://www.mturk.com/) или в [Толоку](https://toloka.ai/) мы не можем отдать, чтобы кто попало размечал рентгеновские снимки, есть здесь рак или нет, например. 
Затем стали для разметки использовать transfer learning, то есть обученные на других задачах модели пытаются разметить нужным нам образом датасет.

Появились подходы к программируемым датасетам, когда мы пишем некоторое количество простых правил, слабых лернеров, и запускаем программную разметку датасета. Библиотека [Snorkel](https://www.snorkel.org/) реализует в себе вот эту логику, когда мы пишем простые разметчики, которые, например, для 5% данных могут дать хороший результат, а для остальных они говорят, что мы не знаем. И вот эту разметку, сделанную алгоритмами, людьми, библиотека Snorkel позволяет объединить и построить более-менее непротиворечивый набор разметки. 

**Semi-supervision learning**, то есть обучение со слабым учителем. Есть технология semi-supervision, которую продвигает [v7Labs](https://www.v7labs.com/blog/semi-supervised-learning-guide), у них есть стартап, и много документации по теме. Это когда мы размечаем часть наших данных, потом на этой части данных учим модель, и этой моделью мы размечаем остальные данные, и потом те данные, которые наша модель разметила с большой уверенностью, мы тоже используем как разметку. 

Есть подход, называемый **active learning**, когда мы размечаем какое-то количество данных, и затем в оставшихся неразмеченных мы ищем те данные, разметив которые, мы сильнее всего улучшим качество модели. 

Еще очень часто самую большую отдачу при работе с данными дает **чистка их от ошибок**. Например, очистка от ошибки разметки или просто исключение каких-то данных, которые сбивают с толку модели. Есть стартап и опенсорсная библиотека [CleanLab](https://github.com/cleanlab/cleanlab), которая позволяет искать противоречивые данные, когда у похожих данных разная разметка.  

**Что мы можем делать с данными, если мы нашли противоречия в них?** Ну, возможно, это ошибка, их нужно переразметить. А возможно, действительно, в мире все неоднозначно, и нам нужно оставить оба варианта разметки. Это надо решать с экспертами предметной области, но в любом случае такие точки надо находить и работать с ними. И CleanLab предоставляет удобные сервисы для проверки данных на ошибки и противоречия. 


**Если вы возьметесь за ручную разметку данных, сразу помните, что это долго, дорого и не очень качественно, но иногда другого варианта нет.** За рубежом обычно пользуется Amazon Mechanical Turk, где задача выдается людям, которые за деньги размечают вам данные. Есть хороший стартап [Scale](https://scale.com/), который поддерживает разные модели разметки, в том числе semi-supervised learning, о котором мы говорили. Есть удобный инструмент [LabelBox](https://labelbox.com/). И есть два стартапа, которые выросли в России - это [LabelMe](https://labelme.ru/), который обеспечивает для вас разметку данных, и Толока. Это аналог Amazon Mechanical Turk, и на мой взгляд, он даже лучше, чем Amazon Mechanical Turk.

Тут надо помнить, что, отдавая данные на разметку в Толоку, вам надо обеспечить, чтобы, если кто-то разметил вам данные неправильно, вы смогли это понять. На практике это обычно так: вы отдаете каждую задачу на разметку хотя бы трем людям. Или двум, а третьему - если у них не совпала разметка. И есть библиотека, которая реализует вот эту логику повторной разметки, то есть проверки качества с Толоки. 

**Программируемый датасет**
У нас иногда есть хороший способ программно разметить какой-то кусочек данных. Не все данные, а вот, например, кусочек. Например, мы строим модель токсичного текста - текста, который может быть оскорбительным для тех или иных людей. Допустим, у нас есть комментарий на сайте, и мы хотели бы токсичный текст отправлять на премодерацию. Мы не можем однозначно сказать, содержится ли в этом тексте издевка, скрытое оскорбление, тем более, что и люди не всегда это понимают. Но у нас есть набор простых правил - например, короткие тексты обычно не токсичны. Для того, чтобы оскорбить человека, как правило, нужно написать много слов. Тексты с матерными словами обычно токсичны. И, таким образом, мы можем написать некоторые правила, которые разметят нашу модель, пусть не весь набор данных, но часть его. И потом на нашей разметке учить уже более-менее сложную модель. И тут есть наблюдение, что какой-нибудь Bert будет использовать не те признаки, которые мы использовали. То есть маловероятно, что мы совпадем по признакам. Поэтому мы размечали данные по простым тупым признакам, по правилам - а модель выучила сложную логику, которая нам была нужна. **Звучит странно, но это работает.** Общий подход библиотеки Snorkel такой, что мы пишем какое-то количество лейблеров, разметчиков. При этом разметчики могут использовать разную информацию из разных баз данных: какие-то доменные евристики, как я уже говорил, например, что короткий текст обычно не оскорбителен; внешняя база данных, например, вот этого человека забанили как тролля; какие-то паттерны, шаблоны, то есть, например, словарь неприличных выражений. И объединять все это, используя разные признаки, и строить вероятностную разметку, и на ней уже учить модель.

Тут есть два подхода. Первый - это **двухстадийный метод.** Первое - это мы учим вот эту модель разметки, то есть, когда наши простые правила говорят - скорее сработало, скорее не сработало. Если правил много, допустим, у нас девять правил, и четыре правила сказали - да, это скорее всего токсичный текст; два правила сказали - это скорее всего не токсичный текст; а остальные правила сказали - ну, мы не поняли, мы не знаем. То есть разметка была на три класса. И мы можем сказать, что вероятность того, что этот текст не токсичный - в данном случае одна третья. То есть, два правила у нас сказали - не токсичный, четыре - токсичный. Две третьих, что токсичный текст. И мы получили так называемые **мягкие вероятностные метки.**  

Тут отдельно сказать про вероятностные метки - бывает разметка данных жесткая, когда мы говорим, допустим, это токсичный текст или нетоксичный текст. Ноль или один. А бывает мягкая разметка, когда мы размечаем с некоторой вероятностью, что этот текст с вероятностью 0,6 у нас токсичный и с вероятностью 0,4 нетоксичный. Так вот, **для того, чтобы учиться, моделям нужно на порядок меньше мягких меток, чем жестких. То есть, если у вас есть миллион жестких меток и сто тысяч мягких меток, то на ста тысячах меток модель научится, наверное, даже лучше, чем на миллионе жестких.**


Вопрос, где эти мягкие метки взять? И вот, когда у нас есть несколько слабых лернеров, то есть моделей, которые простыми правилами размечают наши данные, мы можем из их ответов сформировать вероятностные метки. И по этим вероятностным меткам уже обучить конечную модель. Единственное, что наша конечная модель должна уметь работать с вероятностными метками - и в библиотеке Snorkel некоторое количество таких моделей, которые умеют работать с мягкими метками, есть.

В принципе, можно взять любую модель, которая позволяет взвешивать строки и заставить ее работать с вероятностными метками. Например, в логистической регрессии у нас есть вес каждой строки, и предположим, что мы хотим дать некоторой строке положительную разметку 0,8. Мы дублируем эту строку и включаем ее два раза. Один раз как, например, токсичный текст с весом 0,8, и второй раз как не токсичный текст с весом 0,2. Внутри модели эти веса используются просто при суммировании лосса, функции потерь. Поэтому мы получим те самые мягкие метки, и модель начнет учиться лучше. Другой подход - это когда мы учим конечную модель непосредственно на данных наших слабых разметчиков. Как это работает? Во-первых, это почти всегда нейронки. Данные слабых разметчиков можно рассматривать как некоторые эмбеддинги. Если у нас допустим, 9 функций разметки, а их может быть и 900, то где-то 0, где-то 1, то есть где-то спам, где-то не спам, где-то токсичный текст, где-то нетоксичный. И мы получили некоторый эмбеддинг, и на этом эмбеддинге мы уже можем учить нейронную сеть принимать решение. Это несколько более сложный, тяжелый в отладке способ, но он тоже хорошо работает. 

Еще раз напомню, что при программном слабом контроле у нас случается магия. **Мы учим, мы размечаем данные по правилам на одних признаках, а модель потом начинает учиться на других. Это нам не гарантируется, но почти всегда так получается, потому что признаки, удобные для модели и признаки, удобные для наших правил - это разные признаки. Обычно.**


Отдельный пример, **как сэмплировать в случае потоковых данных** - то есть если вам, например, повезло работать с потоковыми данными, когда вам постоянно идет набор событий, например, с датчиков или кликстрим, а вам нужно выбрать представительную выборку какую-то из данных. А у нас сегодня с утра зашли, допустим, люди покупать одно, завтра люди покупать другое, потом люди пришли развлекаться - просто ходить по сайту, потом пришли какие-то еще люди из другой категории. То есть, например, с утра нам ходили дилеры покупать товары на сайт оптом, днем люди ходили в обеденный перерыв искать что-то для дома, вечером семейные покупки, ночью импульсивные покупки. То есть нам хотелось бы собирать сэмпл из потоковых данных более-менее представительным, но данные у нас идут неравномерные по времени. И вот тут есть такая техника, как [reservoir sampling](https://ru.wikipedia.org/wiki/Reservoir_sampling) - когда мы выкидываем по определенным правилам данные из потока и собираем набор, который в любой момент готов для того, чтобы взять его в качестве сэмпла. Технология достаточно простая - например, мы случайно берем первые 100 точек и затем, по мере того, как к нам поступают новые данные, мы заменяем эти 100 точек случайным образом на новые. У reservoir sampling есть куча разновидностей, вот [ссылка на статью](https://arxiv.org/pdf/1510.08560.pdf), можно разобрать, как конкретно в вашем случае его делать.