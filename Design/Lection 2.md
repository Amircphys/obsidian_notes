Для большого бизнеса ML системы - это такие же инвестиции, как, например, строительство нового складского центра или открытие нового магазина. Ресурсы всегда ограничены, и задача бизнеса вложить их туда, где они принесут наибольшую отдачу. А значит, нашу ML-систему мы можем рассматривать как какой-то инвестиционный проект.  Мы предполагаем, что эти инвестиции положительно повлияют на наши бизнес-процессы, на прибыль и убытки. Причем повлияют не когда-нибудь, а в обозримой, нужной нам перспективе. Например, в течение года.

Как вообще система может влиять на наши бизнес показатели? Например, мы хотим увеличить прибыль. Прибыль это доходы минус расходы. Мы должны либо увеличить продажи, либо снизить затраты. Мы можем повлиять явно, например, сделать какую-нибудь рекомендательную систему, которая увеличит средний чек или конверсию в интернет-магазине. 

Мы можем **неявно** повлиять на наши бизнес-показатели. Например, увеличить удовлетворенность пользователей. Они будут меньше уходить, у нас уменьшатся затраты на рекламу. Либо мы увеличиваем удовлетворенность персонала, и у нас уменьшится кадровая текучка, люди будут работать эффективнее. Или совсем неявно. Иногда ML-модель нужна не для того, чтобы увеличить операционную эффективность, а для того, чтобы увеличить инвестиционную привлекательность, или перевести операционные затраты в капитальные. О чем это?

Когда мы тратим каждый день 100 000 на наш колл-центр, эти 100 000 мы потратили - и они исчезли. Это операционные затраты. Если же мы 100 000 вкладываем в систему автоматизации колл-центра, то у нас к концу года образовываются капитальные затраты, которые как бы с нами, они принадлежат нам. С точки зрения бухгалтерии это как будто мы купили станок. У нас выросли капитальные затраты, у нас больше имущества. Это интеллектуальная собственность, которая может повлиять на нашу оценку как стартапа, например. Иногда нас любят за то, что мы создаем интеллектуальную собственность, а не повышаем операционную прибыль.

**Если мы не поймем ограничения, если мы не поймем контекст, в котором мы делаем проект, ничем хорошим это не кончится. Мы не сможем сделать его хорошо, потому что смысл любой системы расположен за ее пределами. Мы должны хорошо понимать, зачем бизнес платит за разработку ML-системы.**

Допустим, мы хотим внедрить машинное обучение, чтобы увеличить прибыльность интернет-магазина. Как мы можем ее увеличить? Например, сделать рекомендательную систему, которая при покупке рекомендует пользователю аналогичные товары, или товары, которые дополняют те товары, которые он уже купил, или помогают ему быстро найти нужный товар. 

Как мы будем измерять пользу от нашей модели? **Например, рекомендательные системы для интернет-магазинов любят делать так. Они говорят: "Разместите наш блок на главной странице вверху, и вы увидите, как много покупателей к вам придет с этого блока". Но из нашего опыта - все, что вы повесите на главной странице вверху, будет приводить к вам покупателей.** Любой товар, который вы прорекламируете вверху страницы посещаемого интернет-магазина, будет продаваться в 10 раз лучше, чем если бы он был размещен в другом месте. Тут есть эффект каннибализации пространства на экране. Вы поставили рекомендательную систему, вы улучшили поиск для пользователей для одних товаров, и ухудшили поиск для других. Как мы измерим поиск?

Самый очевидный способ - если мы измерим нашу выручку. **Допустим, у нас выросла выручка. Но выручка, к сожалению, меняется от миллиона разных причин: изменилась погода, изменились цены, курс доллара, обстановка в мире, какие-то акции у конкурентов, скидки, конец года, выплатили премию, задержали премию. Получается, что огромное количество факторов, над которыми мы не имеем контроля, и не измеряем их, влияют на наши продажи. И еще влияет наша рекомендательная система. Получается, что наши метрики зачастую ненадежны, в том смысле, что они зашумлены.** И даже, если бы мы считали такую вполне понятную штуку, как продажи каждого конкретного товара, то большинство товаров  — длинный  хвост распределения — продаются очень редко. И сколько бы у нас ни было этих товаров, продажи их не будут статистически значимы. Вы не сможете набрать за нужный период времени столько продаж, чтобы статистически значимо рассказать, что что-то стало продаваться больше или меньше.

**Метрики**
У нас метрики бывают, во-первых, зашумленные, во-вторых, неудобные. Чтобы работать с более удобными метриками, есть техника прокси-метрики, мы ее упомянем чуть позже, а пока, в принципе, какие у проекта могут быть метрики?

Во-первых, это бизнес-метрики - те метрики, которые измеряют влияние нашего проекта на ключевые показатели бизнеса: прибыль, доля рынка, привлекательность для инвесторов, если мы ее можем замерить. На этом уровне нашим бизнес-пользователям наши F1, ROC-AUC, Accuracy, Precision, Recall интересны только до тех пор, пока бизнес-метрики их радуют. Если будет падать прибыль, доля рынка - им будет плевать на F1, ROC-AUC и все остальное.

И есть инженерные метрики. Инженерные метрики - это могут быть метрики системы, такие как задержка и пропускная способность, и ML-метрики: F1, ROC-AUC, Accuracy, Precision, Recall. Проблема с ML-метриками в том, что на проде мы не всегда можем их измерить. Например, мы выдаем кредиты - задача кредитного скоринга. И о том, что человек не вернет кредит, формально мы узнаем через 90 дней после того, как он просрочил платеж по кредиту. Всякая способность в разумные сроки посчитать наш accuracy у нас отсутствует. И тут нам на помощь приходят прокси-метрики.

[Прокси-метрики](https://habr.com/ru/company/retailrocket/blog/591205/) - это метрики, которые  сами по себе нас не интересуют, но они скоррелировались с интересными нам метриками, и их удобнее мерить. Например, если мы оптимизируем какую-нибудь рекламную кампанию, мы могли бы оптимизировать продажи. Но продажи у нас случаются редко и зашумлены. Мы можем посмотреть, сколько у нас посетителей на сайт пришло. Допустим, при конверсии посетителей на сайте в продажи 2%, этих событий у нас в 50 раз больше, чем продаж. А значит, статистическая значимость больше - мы можем увидеть разницу быстрее.

Иногда мы не можем измерить нашу основную метрику в нужное время, как с кредитом, но мы можем измерить прокси-метрику, похожую метрику. Как правило, бизнес знает свои прокси-метрики, их надо спросить - они все равно их отслеживают без всякого машинного обучения. Если много данных, прокси-метрики можно поискать, исходя из корреляции этих данных. В идеальном случае мы комбинируем найденные нами из корреляции прокси-метрики и знания о бизнесе. Тут есть ссылка на статью Retail Rocket про прокси-метрики, а в дополнительных материалах есть рассказ про то, как Uber искал прокси-метрики в своем бизнесе. Также в дополнительных материалах есть **интересный рассказ про то, как модель сломалась, а выручка выросла. Это модель Microsoft, которая подбирала страницы в поиске Bing. И когда они выкатили неудачную версию модели, пользователи не могли найти то, что им нужно, и смотрели в три раза больше страниц - соответственно, в три раза больше продавалось рекламы. И поэтому формально поиск Bing стал работать в три раза лучше, он стал в три раза больше денег приносить на какое-то время. Понятно, что это краткосрочный эффект. В долгосрочной перспективе пользователи бы ушли, поэтому они исправили эту ошибку. Вообще деньги могут быть очень зашумленным, сбивающим с толку фактором, об этом тоже надо помнить.** 

[Масштабируемость](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%81%D1%88%D1%82%D0%B0%D0%B1%D0%B8%D1%80%D1%83%D0%B5%D0%BC%D0%BE%D1%81%D1%82%D1%8C). Если вы сделаете что-нибудь полезное, это обязательно придется масштабировать. Масштабируемость - это способность системы, сети или процесса справляться с увеличением рабочей нагрузки. Обычно с нагрузкой справляются, добавляя ресурсы. И тут есть два варианта - ваша система может быть способна к вертикальной или горизонтальный масштабируемости. Вертикальная масштабируемость - это когда мы взяли и купили более мощные сервера, они работают быстрее, мы можем обслуживать больше посетителей, больше запросов. Так или иначе, в любом вертикальном масштабировании мы упремся в потолок, и нам понадобится горизонтальная масштабируемость. Горизонтальная масштабируемость - это когда мы можем распределять нашу задачу на много систем, которые ее считают независимой.

Кроме горизонтальной и вертикальной масштабируемости, есть еще масштабируемость вглубь. Практика показывает, что у вас будет расти не только трафик и объем данных - если вы сделаете что-то полезное, у бизнеса будут расти аппетиты, вас попросят добавить еще моделей, еще сценарии использования. В конце концов, вы столкнетесь с тем, что вам нужно управлять версиями моделей, их совместимостью, дообучением, выкаткой и так далее. 

[Обслуживаемость](https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%BC%D0%BE%D0%BD%D1%82%D0%BE%D0%BF%D1%80%D0%B8%D0%B3%D0%BE%D0%B4%D0%BD%D0%BE%D1%81%D1%82%D1%8C) - это отдельная проблема, о которой часто забывают. Большинство проблем после того, как систему удалось запустить, касаются именно масштабируемости и обслуживаемости. Обслуживаемость - это приспособленность к восстановлению работоспособного состояния после отказа и повреждения.

Какие отказы и повреждения тут имеются в виду? Сердцем ML-системы являются алгоритмы. Это, в общем-то, программа, они не ломаются. Но ломаются сервера, на которых они работают, ломаются сети связи, ломаются системы хранения. Нужно уметь определять - насколько наша система устойчива к отказу какого-то элемента, насколько ей нужна такая устойчивость, насколько она хорошо обслуживается, насколько она защищена от глупых решений администраторов. Потому что первичные администраторы системы, те, которым мы передадим систему с рук на руки, скорее всего, будут понимать, что происходит, как она работает, как правильно с ней обращаться, как ее обновлять, как ее мониторить. А те, кто придет им на смену через полтора года - будут ли они понимать, как с ней жить?

 [адаптируемость](https://en.wikipedia.org/wiki/Adaptability) - это способность адаптироваться к меняющимся обстоятельствам. Кроме структуры данных, меняются еще и бизнес-требования, доступность данных, законодательство, оборудование, инфраструктурные сервисы. То есть сегодня мы сидели на Kafka, а завтра зачем-то перешли на Rabbit, и нам пришлось переписывать это все. Сегодня заказчик сидел гордо на Oracle, завтра Oracle перестал его поддерживать, и все начали мигрировать на Postgres, а нам со всем этим жить.

Кроме всего прочего, есть смена распределения данных — **data shift** и **target drift**.

Проще всего сдвиг данных объяснить на примере с Computer Vision. Когда до ковида мы обсуждали проблемы сдвига в распределении данных с коллегами по отрасли, ребята, которые занимаются Computer Vision, мне говорили: "У нас таких проблем нет, лица людей всегда одинаковые". Прошел месяц, начался ковид, на лица людей надели маски. Пришлось переучиваться. Мир меняется, и те данные, которые вам приходят, могут быть другими. **Обо всем этом нужно подумать еще на этапе дизайна системы**. 

Начав работать над проектом, мы столкнемся с проектными ограничениями. **Правило большого пальца: примерно пятая часть работы - это запуск нашей системы, а 4/5 - это ее доработка, то есть что-то, что нам забыли сказать, что-то, о чем мы забыли подумать, или какие-то непредсказуемые вещи, которые все равно придется доделывать.** Наши ограничения - данные, деньги, оборудование, люди - то, что позволяет нам сделать и успешно завершить проект - могут нас здорово ограничить в достижении целей, в инструментах, которые мы используем, в качестве, которого можем достигнуть. **Самое большое ограничение обычно - это данные.** Денег можно занять, выбить, превысить бюджет по деньгам. Каждый второй проект в IT превышает бюджет по деньгам. Оборудование можно купить новое, людей можно постараться нанять. Но если нет данных, скорее всего, проект не взлетит, или его нужно сначала переформулировать как проект по сбору данных. 
Как показывает практика, **обычно проблемы не в качестве ML-модели, не в ее архитектуре, а где-то на границах системы. Либо нам приходит не то, что мы ожидали, либо то, что мы выдаем, нельзя использовать там, куда мы его отдали.**

**Compliance and privacy**. Как только мы начинаем работать с данными, нам хочется отдать их кому-нибудь на разметку. Не всегда мы можем отдать данные на разметку. Медицинские данные мы почти всегда не можем отдать на разметку. Можем ли мы хранить данные в облаке? Во многих странах есть ограничения на хранение данных за границей, есть ограничение на хранение данных зашифрованными, иногда данные нужно шифровать определенными алгоритмами. Некоторые данные пользователей мы собирать не имеем права. Иногда мы не имеем права использовать сторонние сервисы.

**Технические ограничения.** Технические ограничения обычно связаны с проблемой интеграции нашей системы в существующую систему заказчика. Нам так или иначе приходится получать данные и загружать данные обратно. Если у заказчика уже есть какая-то система, которая решает проблему, на которую мы нацелились, то нам нужно будет превзойти качество существующей системы. Причем не просто превзойти, а документированно превзойти, чтобы доказать, что заказчик потратил силы не зря. Нам желательно переиспользовать имеющуюся инфраструктуру заказчика, а значит, нам нужно провести ревизию этой инфраструктуры и понять, что из его инфраструктуры можем использовать.

После того, как мы придумали саму систему, нам нужно так или иначе разработать сердце системы - ML-модель. **Общее правило большого пальца во внедрении ML - это попробовать обойтись без внедрения ML, сделать решение без ML, если возможно.** Многие ML-модели можно без значительной потери качества заменить какими-то простыми if-ами, выбором из таблицы значений. Нам желательно замерить качество, которое мы получаем в такой простой модели, и затем сравнивать, насколько мы смогли его улучшить, добавив простые, а потом и сложные ML-модели. Если мы начинаем решение нашей проблемы с нейронной сети (сразу сложной модели), и мы получили какое-то качество, то мы не знаем - может быть, всегда предсказывая одно и то же, мы получили бы качество и получше.


**Начинать надо именно с baseline.** Прежде, чем улучшать качество, прежде, чем учить модель и смотреть, насколько она хорошо работает, нужно сначала найти какой-нибудь baseline. **Идеальный baseline - это существующие на рынке решения.** Если есть у вас конкурент, подпишитесь на его API, прогоните данные через его API, посмотрите какое качество у него есть. Вот вам будет baseline.

**Простое решение на правилах. Если у вас есть возможность, можно оценить, как много ошибок делают люди. Скорее всего, вы не сможете превзойти качество людских оценок, потому что вы учитесь на разметке, сделанной людьми.** Мы можем построить модели, которые принимают решение качественнее, чем человек, но для этого нам нужна разметка более качественная, чем делают люди. То есть какого-то сверхчеловека надо поймать, чтобы он нам данные разметил, тогда у нас будет сверхкачество. Этого обычно достигают, заставляя людей размечать данные консилиумом, или ансамблируя оценки нескольких людей, то есть строят ансамбль из людей так же, как строят ансамбль из моделей машинного обучения.

По требованиям к качеству - любой заказчик хочет, чтобы вас была 100% accuracy, 100% recall. Но тут надо понимать, что в реальности мы всегда остаемся с каким-то уровнем ошибок. Этому есть чисто математические причины и организационные причины. Есть некоторый идеальный байесовский классификатор и ошибка идеального байесовского классификатора, выше которой на этих данных не прыгнешь, потому что обычно данные чуть-чуть, но противоречат сами себе. В самоуправляемом автомобиле, который выбирает путь, обычно высокие требования к качеству. А если вы в мобильном телефоне набираете текст, и модель подсказывает, какое слово будет следующим, там не такие высокие требования - если модель вам подскажет не то слово, вы посмеетесь и исправите его руками. Рекомендации в интернет-магазине - даже если вам порекомендуют совсем не то, что вы ищете, то вы найдете нужный вам товар в поиске и все равно его купите. Очень трудно формализовать разумный уровень качества. Хорошо попробовать выразить в деньгах. Например, насколько вырастет прибыль, если увеличить accuracy на 1%? Обычно заказчик не может ответить на этот вопрос. Если вместе с ним начать искать ответ на этот вопрос, может быть, требования к вашей модели станут более реальными. **Все это приводит к тому, что критерий нам приходится искать итеративно. То есть мы выбираем какую-то метрику, которую мы будем оптимизировать, собираем данные, разметку, готовим признаки, учим модель, выясняем, что в наших данных очень много мусора, и мы не можем достигнуть нужного нам качества, ищем ошибки, исправляем, переобучаем модель, выгружаем модель и выясняем, что вроде бы по метрике все хорошо, но модель работает неправильно. Подбираем подходящую метрику, возвращаемся к обучению модели и крутимся по кругу до тех пор, пока не придем к устраивающему нас и заказчика итогу.** 