
### Осторожнее с SOTA
Почему надо быть осторожнее с современными state-of-the-art решениями? Очень часто это решение никто не пробовал в продакшене. То есть оно может быть сильно медленнее, требовать сильно больше памяти, дольше считаться. Для него может не быть готовых библиотек, оно может не работать на больших или наоборот на маленьких наборах данных. Например, ему надо очень много данных для того, чтобы завестись. А еще оно может вообще не работать. То есть то, что оно опубликовано в статье, в которой описано, что она всех превосходит, вообще не значит, что это подход работоспособный - иногда бывает и так.

### Начинайте с простой модели
Всегда начинайте с простой модели, причем с простой в алгоритмическом смысле, а не в смысле усилий. То есть, как правило, проще взять готовый Bert и им обработать, но у него много предположений скрыто под капотом. Вы не увидите какие-то проблемы данных, не увидите базовые проблемы на входе и выходе. Кроме того, простая модель обычно проще в развертывании. И, поскольку ML-модель - это сердце вашей ML-системы, то простая модель делает проще всю систему. Она проще в отладке.
На самом-то деле ошибки на входе и выходе, то есть мусор, который вам приходит, и проблемы с применением вашего предсказания, которое вы уже сделали, обычно являются большими проблемами, чем качество вашей модели. То есть вы можете построить прекрасную модель, но пользователь передаст вам какие-нибудь неполные или странные данные или не сможет пользоваться тем предиктом, который вы сделали по его техническому заданию. **В общем, сделайте как можно раньше как можно более простую модель. И все равно вам понадобится baseline, чтобы сравнивать ваши сложные модели. Вот это и будет ваша простая модель baseline.**

### Ошибки в сравнении моделей
При сравнении моделей очень легко наступить на грабли, специфичные именно для сравнения моделей. Предположим, что мы очень хорошо умеем работать с градиентным бустингом и не умеем работать с нейронными сетями. И тогда мы при обучении модели на градиентном бустинге хорошо ее оптимизировали, подобрали гиперпараметры, а нейронную сеть сделали как попало. И понятно, что наш градиентный бустинг будет работать лучше. Получается, что мы как бы сравнили две модели и выбрали лучшую - но на самом-то деле нейронную сеть мы не доучили. То есть модели в принципе трудно сравнивать, особенно разные архитектуры. И надо экспериментировать с гиперпараметрами, отслеживать эксперименты, чтобы потом, когда вы поймете, что модель надо было настраивать, может быть, перезапустите и сравните результаты. ==И всегда сомневайтесь в результатах сравнения моделей.==
Мы можем оценить так называемый [learning curve](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html), кривую обучения. Обучить нашу модель на небольшом количестве примеров, допустим на четверти примеров, потом на половине, потом на двух третьих и смотреть, как качество модели на трейне и тесте меняется. И если качество модели на трейне и тесте неуклонно растет по мере увеличения объема данных, то мы можем сделать обоснованное предположение о том, как оно будет расти по мере появления новых данных. И возможно, что модель, которая лучше прямо сейчас, будет сравнительно сильно хуже потом, когда данных будет много. Это часто происходит, например, с нейронками.

### Компромиссы
Ошибки первого и второго рода - это ==понятия, используемые в статистике при проверке гипотез==. Ошибка первого рода (α-ошибка, ложноположительная) возникает, когда верная нулевая гипотеза ошибочно отвергается. Ошибка второго рода (β-ошибка, ложноотрицательная) возникает, когда неверная нулевая гипотеза принимается. В контексте проверки гипотез, нулевая гипотеза - это утверждение об отсутствии эффекта или разницы. Принятие или отклонение нулевой гипотезы основано на анализе данных и заданном уровне значимости (α).
- **Ошибка первого рода (α-ошибка):**  
    Представьте, что вы проводите тест на беременность, и он показывает положительный результат, хотя вы не беременны. Это пример ошибки первого рода. В статистике это означает, что вы отвергли нулевую гипотезу (например, "нет беременности"), хотя она на самом деле верна. Вероятность совершить ошибку первого рода обозначается α, и она обычно устанавливается на уровне 0.05 или 0.01, что означает, что существует 5% или 1% вероятность совершить такую ошибку.

- **Ошибка второго рода (β-ошибка):**
    Продолжая пример с тестом на беременность, это когда тест показывает отрицательный результат, хотя вы беременны. Это ошибка второго рода, когда вы не отвергли нулевую гипотезу (например, "нет беременности"), хотя она неверна. Вероятность совершить ошибку второго рода обозначается β. Уменьшение вероятности одной ошибки обычно увеличивает вероятность другой, и в статистике часто стремятся найти баланс между ними.
Выбор, например, между Precision и Recall. Выбор между Precision и Recall - это фактически выбор между ошибками первого и второго типа. Что нам важнее - чтобы среди тех, кому мы дали кредит, было больше людей, способных его отдать, или чтобы среди тех людей, которые к нам пришли, мы нашли больше кредитоспособных заемщиков? Это разные задачи, и одна из них оптимизируется по Precision, а вторая по Recall. В медицине очень часто оптимизируют модели под Recall, потому что нам, например, гораздо важнее поймать на скрининге рак или туберкулез, пусть даже это окажется ложной тревогой, но не хотелось бы его пропустить, потому что человек умрет. В промышленности, в торговле, может быть, нам стоит упустить какой-нибудь потенциально прибыльный вариант, потому что потери в случае ошибки будут очень большие.

Следующий компромисс, с которым все время приходится работать - это **качество против сложности развертывания**, качество работы модели. Обычный вариант - это выбор между нейронками, градиентным бустингом и, например, логрегом, логистической регрессией. Если, конечно, такой выбор стоит, то логистическая регрессия деплоится очень просто, деревья и градиентные бустинги тоже деплоятся просто, в с нейронными сетями приходится повозиться.

**Качество vs задержка инференса.** Некоторые модели могут быть очень качественными, но медленными. Например, предположим, что мы хотим создать текстовое описание картинки. Мы можем взять image-to-text модель, которая генерирует текст по картинке - например, "человек в красной куртке стоит на снегу". Это будут описания высокого качества, мы можем удобно их использовать для поиска по картинкам, но они будут медленно генерироваться. Другой вариант - использовать YOLO, которое выделяет объекты на фотографии, и использовать ResNet для быстрой классификации этих объектов, например, до классификации, дообученной на наших картинках. Или сразу YOLO дообучить на наших картинках. Таким образом, мы можем с очень большой скоростью выдавать список объектов, которые есть на картинке, и, конечно, это не будет такой связный текст, как "человек в красной куртке стоит на снегу, глядя за горизонт". Но там будут ключевые слова - "человек", "куртка", "снег", и, может быть, нам для поиска этого и хватит. Зато это будет очень быстро.

**Качество vs эксплуатационные издержки.** Это очень частая история - когда мы разворачиваем нашу модель, нам приходится платить за хостинг. Мы можем развернуть нейронные сети - мы будем оплачивать GPU-сервера; мы можем развернуть, допустим, градиентный бустинг - и он, например, будет считаться на CPU. На самом деле, нейронки тоже могут считаться на CPU, но, допустим, NLP-шные модели на GPU считаются явно веселее. И стоимость эксплуатации этих моделей будет совершенно разная.

**Качество vs устойчивость к атакам.** Тут, опять же, сложные модели иногда можно просто обмануть. Многие сложные модели уязвимы к adversarial-атакам, когда мы можем добавить небольшой шум на картинку, в данный или в текст, и модель сменит свое решение на то, которое хотел от нас атакующий. А простые модели более устойчивы к ним. Также они более устойчивы к случайному шуму, и нам всегда нужно понимать, что нам важнее - качество или устойчивость, качество или эксплуатационные ресурсы.

### Предположения модели

Каждая архитектура модели делает какие-то предположения. Например, [линейная регрессия](https://towardsdatascience.com/assumptions-of-linear-regression-fdb71ebeaa8b). Ее предположения просто проходят в университете - базовое предположение линейной регрессии, гомоскедостичность и так далее. Но на практике их редко проверяют. [Сверточные сети](https://cs231n.github.io/convolutional-networks/) предполагают локальность на картинке. Например, если у вас на картинке сфотографировано яблоко, то точки яблока, они локальны, они расположены рядом. Кроме всего прочего, сверточные сети предполагают инвариантность, яблоко можно сдвинуть на 100 пикселов вправо или влево, и это все равно останется яблоком. 
Другой вариант, прямо противоположный - люди пытались анализировать с помощью сверточных моделей зашифрованный текст, или генераторы случайных чисел. Но дело в том, что в генераторе случайных чисел локальности быть не должно. То есть две соседние точки на картинке, сгенерированные генератором случайных чисел - они должны быть не связаны между собой.

Марковские модели предполагают, что процесс у нас без памяти.
Кластеризация предполагает, что в пространстве, в котором мы оцениваем взаимное расположение наших точек, есть метрика, и эту метрику можно сравнивать - есть локальность, есть понятие дистанции, и мы можем объединять точки, у которых дистанция между собой меньше, и разделять точки, у которых дистанция между собой больше. Предположение о метрике часто нарушается, когда кластеризацию делают поверх сложного снижения размерности. Например, если мы делаем линейное снижение размерности, например, PCA, principal component analysis, там можно считать, что метрика сохраняется, а в модели t-SNE, когда мы нелинейно преобразовываем наше пространство, у нас близко расположенные точки расположены близко, далеко расположенные точки у нас расположены далеко, но больше, кроме этого, у нас ничего нет. То, что одна точка чуть дальше, чем другая, ничего не говорит, и кластеризацию поверх t-SNE надо делать очень осторожно.

**Итого, при выборе модели нам нужно избегать модных моделей, начинать с самой простой, всегда делать поправку на человеческие ошибки, пытаться предсказать, как качество модели изменится в будущем и изучать ограничения предположения модели.**

### Ансамбли моделей

Качество работы модели можно увеличить, собрав несколько моделей вместе и объединив каким-нибудь способом их предсказания. Обычно это называют [стекингом](https://alexanderdyakonov.wordpress.com/2017/03/10/c%D1%82%D0%B5%D0%BA%D0%B8%D0%BD%D0%B3-stacking-%D0%B8-%D0%B1%D0%BB%D0%B5%D0%BD%D0%B4%D0%B8%D0%BD%D0%B3-blending/), тут есть [терминологическая путаница](https://medium.com/@stevenyu530_73989/stacking-and-blending-intuitive-explanation-of-advanced-ensemble-methods-46b295da413c) - что у нас стекинг, что у нас блендинг и так далее и тому подобное. По ссылкам - некоторое разъяснение всего этого. Популярные готовые ансамбли - это градиентный бустинг и случайный лес.

Тут почти всегда не имеет смысла ансамблировать слабые алгоритмы. Это, кстати, популярная ошибка на kaggle - когда учат много слабых и сильных моделей, а потом собирают их в кучу. Качество получившейся модели хуже, чем качество одной из самых сильных моделей. Не имеет смысла ансамблировать сильно скоррелированные алгоритмы, потому что они ошибаются одинаково, и от того, что вы их ансамблируете, собираете в кучу, ваша ошибка не уменьшится. Тут есть интересное исключение - это алгоритмы weak supervision типа [Snorkel](https://www.snorkel.org/blog/weak-supervision), когда мы строим очень много очень слабых и иногда скоррелированных алгоритмов, и все равно они работают хорошо.

## Отслеживание экспериментов

Когда мы выбираем модель, нам очень важно отслеживать эксперименты. Нам нужно проверить много гипотез обычно, может быть, сотни. У нас будут меняться модели, меняться признаки, сами по себе данные будут меняться и еще очень часто при разных запусках модели мы будем получать разное качество. С этим надо бороться, но у нейронных сетей иногда этого очень трудно избежать. То есть вы учите нейронную сеть и получаете разные нейронные сети на тех же самых данных и даже на том же самом random seed. Так бывает.

Для отслеживания процесса обучения модели есть набор хороших инструментов, и лучший из них - это [Weights and Biases](https://wandb.ai/site). Он, к сожалению, очень платный. То есть не просто платный, а очень платный. Но для личного использования он бесплатный, его можно использовать. Есть хороший открытый набор инструментов [MLFlow](https://medium.com/optuna/easy-hyperparameter-management-with-hydra-mlflow-and-optuna-783730700e7d), в котором можно добавить, например, Optuna для подбора гиперпараметров и Hydra для перебора и хранения конфигураций экспериментов. По ссылке есть хороший пример, как это делать.

Инструменты для отслеживания версионирования моделей есть в [DVC](https://dvc.org/). DVC тем хорош, что он сохраняет слепки данных вместе с вашим пайплайном обучением модели. Это иногда очень хорошо, особенно когда данные маленькие. Вы их поучили и над ними экспериментируете. Когда данные идут к вам потоком и когда данные не помещаются к вам на компьютер, DVC использовать сложнее. Но и там можно, потому что, как правило, мы выполняем какую-то предобработку, и вот результат этой предобработки мы можем сохранять в системе контроля версии.

Инструменты [ClearML](https://clear.ml/) и [CometML](https://www.comet.com/site/) позволяют отслеживать обучение модели. [TensorBoard](https://tensorboard.dev/) - это очень удобный бесплатный инструмент, который позволяет вам передавать из модели разную статистику во время обучения, и делиться ей, и отслеживать. Есть сайт [mymlops.com](https://mymlops.com/), где для каждого этапа работы с моделями собраны примеры инструментов, которые можно использовать. Такой конструктор - собери свой MLOps пайплайн.

### Распределенное обучение

Важная часть работы с нейронками - это как распределить обучение, чтобы оно шло быстрее. Вы можете раздобыть несколько GPU и учить модель на них. Есть хорошие библиотеки, которые позволяют распараллелить обучение для нейронных сетей - это [Accelerate](https://huggingface.co/docs/accelerate/usage_guides/big_modeling) и [DeepSpeed](https://www.deepspeed.ai/). Есть библиотеки, позволяющие распараллелить вычисления, такие библиотеки общего назначения, например, [Ray](https://www.ray.io/ray-sgd) и [LZY](https://lzy.ai/docs/7-integrations.md). [DaskML](https://ml.dask.org/) - это набор библиотек для распределенного обучения на основе Dask. Dask и Ray - очень похожие подходы, там есть тонкое различие, но, в общем, на практике можно пользоваться и тем, и другим. Я бы сказал, что Dask - это больше распараллеленный Pandas, а Ray - это больше распараллеленное вычисление общего назначения. На самом-то деле у Dask есть scheduler общего назначения, а у Ray есть коннекторы, позволяющие параллелить наше вычисление над Pandas, поэтому они более-менее взаимозаменяемы. На обоих этих библиотеках построены стартапы, в которых можно брать облачные ресурсы в аренду. Ну, и Ray, и Dask можно запускать на своих мощностях и даже на одном компьютере.

### Подбор гиперпараметров

При обучении модели нам приходится подбирать гиперпараметры. Тут у нас есть набор хороших инструментов [Optuna](https://optuna.readthedocs.io/en/latest/) и [Hyperopt](http://hyperopt.github.io/hyperopt/) - это байесовские оптимизаторы, и [TPOT](http://epistasislab.github.io/tpot/) - оптимизатор на основе генетических алгоритмов. Обычно подбор гиперпараметров не относят к AutoML, но я тут привел вместе и библиотеки для подбора гиперпараметров, и библиотеки AutoML, потому что разница между ними стирается. [Auto-PyTorch](https://github.com/automl/Auto-PyTorch) - это библиотека, которая позволяет вам построить модель на основе PyTorch автоматически, придумав все нужные части, подобрав. [Auto-sklearn](https://github.com/automl/auto-sklearn) берет алгоритмы из библиотеки scikit-learn и строит из них на основе ваших данных пайплайн, который лучше будет решать вашу задачу. И [AutoML Book](https://www.automl.org/book/) - это хороший твердый такой рассказ о том, как оно бывает. У них есть своя библиотека, но заодно они очень подробно рассказали, что вообще есть в этом мире AutoML.
![[Pasted image 20250712135220.png]]
Обычно, если график прыгает вверх и вниз, это говорит о том, что у нас просто слишком большой learning rate, например, или плохой оптимизатор, который не умеет работать в этих условиях. Большинство оптимизаторов содержат настройки по поводу learning rate, инерции и так далее и тому подобное, то, что называется momentum. Там нужно покрутить эти настройки. Обычно они работают из коробки, но надо смотреть по месту.

Ситуация, нарисованная на левом нижнем графике - это когда у нас произошел так называемый взрыв градиентов, то есть модель вычислительно нестабильна. Обычно это из-за большого learning rate, но может быть и по другим причинам. Тут надо попробовать снизить learning rate, например, в три раза или на порядок и посмотреть, как оно будет.

Идеальная модель - справа вверху. Мы видим, что train у нас все время падает, а test с какого-то момента начинает расти. Вот тут обычно говорят - мы переобучили модель, нам нужно учить ее меньше. Но практика на самом деле показывает, что в этот момент надо успокоиться, пойти выпить кофе и дать модели поработать еще как минимум в 10 раз столько, сколько ей понадобилось для того, чтобы дойти до оптимальной точки, где качество на train и test начали расходиться. Это так называемый **двойной спуск**. Очень часто бывает, что если подождать, то модель сначала снова начнет падать качество на тесте, а потом она упадет еще ниже, чем была вот в этом первом оптимуме. Про двойной спуск есть много интересных специальных статей, но у нас тут, к сожалению, курс не про машинное обучение, а про модели. Поэтому если вы увидели, что ваша модель как бы переобучилась, не пугайтесь - попробуйте поучить ее дальше.

И последний вариант - в правом нижнем углу, когда модель вроде бы как у нас училась, а затем начала странно прыгать в качестве. Обычно это говорит о том, что у вас плохо отсортированные примеры в батчах. Например, если вы учите модель различать кошечек от собачек, а у вас один батч состоит целиком из кошечек, другой батч целиком из собачек - тут надо следить за сэмплированием.

### Калибровка модели
С [калибровкой модели](https://scikit-learn.org/stable/modules/calibration.html#calibration) это отдельная история. О чем это? Когда мы делаем классификатор, он нам выдает какое-то предсказание от нуля до единицы о том, допустим, есть ли на фотографии объект нужного класса. Очень легко совершить ошибку - интерпретировать это значение от нуля до единицы, как вероятность. То есть нулевая вероятность, что тут есть объект, или стопроцентная вероятность, что тут есть объект.

А на самом-то деле модели, особенно нейронные сети к этому склонны, они выдают некалиброванные вероятности. То есть они обычно очень уверены в своих предсказаниях. То есть, если, например, из данных следует, что тут, скорее всего, на картинке нет яблока, модель скажет - ну, вероятность яблока, допустим, 0,01. А если, может быть, есть яблоко, а может и нет, модель скажет - ну, вероятность, что тут есть яблоко, 0,7. А если есть, она скажет - 0,99. То есть модели в принципе переобучаются к более категоричным предсказаниям. С этим можно бороться, но самый простой способ - это брать предсказания моделей и калибровать их. Делать так, чтобы, уж если модель предсказала вероятность 0,6, то именно на 60% тех, кому она предсказала, что на картинке есть яблоко, было действительно яблоко. Делается это через специальную процедуру калибровки модели, когда мы откладываем часть наших данных и потом на них проверяем скалиброванность.

Для калибровки есть модели в scikit-learn, [CalibratedClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV). Для моделей на деревьях обычно используют [Calibration Trees](https://arxiv.org/abs/1808.00111). Тут идея простая. Мы строим дерево решения, которое предсказывает нам, где находится какая точка в данных, а затем мы используем номера листов этого дерева как признаки для логистической регрессии, и ей уже мы предсказываем нашу вероятность. Мы калибруем ей нашу модель. Звучит, может быть, сложно, но пишется руками в 10 строк, и вот по ссылке есть описание.

И для нейронных сетей самый хороший вариант их калибровки - это использовать [softmax с температурой](https://arxiv.org/pdf/1706.04599.pdf). То есть, как правило, на выходе классификатора стоит [softmax](https://en.wikipedia.org/wiki/Softmax_function) - функция, которая приводит сумму вероятности к единице, повышает вероятность самого вероятного класса и снижает вероятность менее вероятного класса. И вот в эту формулу вычисления softmax можно добавить константу, так называемую температуру, которая сделает решение модели более или менее категоричными.

Ну и, кстати, есть такая городская легенда, что логистическая регрессия не требует калибровки, что она выдает откалиброванные вероятности. На самом деле нет. Все модели отдают некалиброванные вероятности, просто логистическая регрессия теоретически тут должна была быть гораздо лучше.

А еще, вне всякой связи с предыдущим, попробуйте [Lightning](https://lightning.ai/). Lightning это библиотека, позволяющая упростить весь цикл обучения, тренировки, инференсы моделей.