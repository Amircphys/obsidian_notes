
1. Таким образом, задачи классификации и регрессии можно сформулировать как поиск отображения из множества объектов $X$ в множество возможных таргетов.
  2. Мы бы хотели найти такое отображение, которое лучше всего приближает истинное соответствие между объектами и таргетами.
  3. Мы хотим искать решение только в каком-то заранее заданном параметризированном семействе функций.
  4. Разделяющее правило: там, где значение функции положительно, мы будем предсказывать один класс, где отрицательно – другой.
  5. Простейшим примером постановки задачи линейной регрессии является метод наименьших квадратов.
  6. Мы хотим моделировать зависимость $y$ от $x$ как линейную функцию со свободным членом.
  7. Мы хотим, чтобы на нашем датасете (то есть на парах $(x_i, y_i)$ из обучающей выборки) модель как можно лучше приближала истинную зависимость.
  8. Функция, оценивающая то, как часто модель ошибается, традиционно называется функцией потерь, функционалом качества или просто лоссом (loss function).
  9. Регуляризация. Малые погрешности признаков сильно возрастают при предсказании ответа, а в градиентном спуске накапливается погрешность из-за операций со слишком большими числами.
  10. Мы хотим обучить линейную модель так, чтобы плоскость, которую она задаёт, как можно лучше отделяла объекты одного класса от другого.
  11. Мы хотим минимизировать число ошибок классификатора, Такая фунция потерь называется misclassification loss. Она кусочно-постоянная, и из-за этого всю сумму невозможно оптимизировать градиентными методами. Но мы можем мажорировать её какой-нибудь более гладкой функцией
	  ![[Pasted image 20250415093747.png]]
	**misclassification loss** - штраф в 1 для всех нерпавильно классифицированных точек и 0 для остальных (правильных точек). Она кусочно-постоянная, и из-за этого всю сумму невозможно оптимизировать градиентными методами: ведь её производная равна нулю во всех точках, где она существует. Но мы можем мажорировать её какой-нибудь более гладкой функцией, и тогда задачу можно будет решить.
	 **Ошибка перцептрона**  - считать отступы только на неправильно классифицированных объектах и учитывать их не бинарно, а линейно, пропорционально их размеру. Она решает задачу линейной классификации, но у неё есть одна особенность: её решение не единственно и сильно зависит от начальных параметров (может решить задачу неоптимально - провести разделяющую плоскость вблизи одного из классов)
	 **Hinge loss, SVM** - штраф в 1 - М для всех отступов меньших 1, объекты, которые проклассифицированы правильно, но не очень "уверенно" (M<1), продолжают вносить свой вклад в градиент и пытаются "отодвинуть" от себя разделяющую плоскость как можно дальше.![[Pasted image 20250415094655.png]]
	 Итоговое положение плоскости задаётся всего несколькими обучающими примерами. Это ближайшие к плоскости правильно классифицированные объекты, которые называют **опорными векторами** или **support vectors**. Весь метод, соответственно, зовётся методом **опорных векторов**, или **support vector machine**, или сокращённо **SVM**. Начиная с шестидесятых годов это был сильнейший из известных методов машинного обучения. В девяностые его сменили методы, основанные на деревьях решений, которые, в свою очередь, недавно передали «пальму первенства» нейросетям.
	
12. **Вопрос на подумать**. Предположим, что у нас есть два классификатора с примерно одинаковыми и достаточно приемлемыми значениями интересующей нас метрики. При этом одна почти всегда выдаёт предсказания с большими по модулю отступами, а вторая – с относительно маленькими. Верно ли, что первая модель лучше, чем вторая?
```
На первый взгляд кажется, что первая модель действительно лучше: ведь она предсказывает «увереннее», но на самом деле всё не так однозначно: во многих случаях модель, которая умеет «честно признать, что не очень уверена в ответе», может быть предпочтительней модели, которая врёт с той же непотопляемой уверенностью, что и говорит правду. В некоторых случаях лучше может оказаться модель, которая, по сути, просто отказывается от классификации на каких-то объектах.
```
13. Почему же SVM был столь популярен? Из-за небольшого количества параметров и доказуемой оптимальности. 
14. . Другие замечательные свойства SVM: существование уникального решения и доказуемо минимальная склонность к переобучению среди всех популярных классов линейных классификаторов. 
15. . Кроме того, несложная модификация алгоритма, ядровый SVM, позволяет проводить нелинейные разделяющие поверхности.
16. . В случае SVM функцию потерь можно написать в таком виде что она будет зависеть от попарных скалярных произведений векторов признаков для объектов $\langle x_i x_j \rangle$ (Теорема Каруша–Куна–Таккера, обобщает теорему Лагранжа обобщает об условном экстремуме функции)
17. . Теперь вместо скалярных в исходном пространстве, можно взять функцию ядра $K(x_i, x_j)$, которая соответствует скалярному произведению образов векторов $x_i, x_j$ в некотором пространстве более высокой размерности, возможно, даже бесконечномерном. Это пространство называют спрямляющим.
18. . Какие бывают ядра? Гауссовское ядро: $$K(x, x') = \exp(- \frac{||x - x'||^2}{2\sigma^2})$$ Спрямляющее пространство здесь бесконечномерно.
19. . Также довольно часто используют полиномиальное ядро степени  $d$: $$K(x, x') = (\langle x, x'\rangle + c)^d$$, $c \geq 0$ - параметр, который определяет влияние на результат мономов высоких и низких степеней.
20. Логистическая регрессия -  появляется из желания посмотреть на классификацию как на задачу предсказания вероятностей. 
21. Метод максимума правдоподобия для распределения Бернулли. Правдоподобие позволяет понять, насколько вероятно получить данные значения таргета у при данных X
22. Более корректным будет подобрать этот порог отдельно, для уже построенной регрессии минимизируя нужную вам метрику на отложенной тестовой выборке. Например, сделать так, чтобы доля положительных и отрицательных классов примерно совпадала с реальной.
23. . $$logloss = log(1+\exp{(-y_i(wx_{i}))}); \quad y_i={-1, 1}$$
24. Отдельно заметим, что метод называется логистической _регрессией_, а не логистической _классификацией_ именно потому, что предсказываем мы не классы, а вещественные числа – логиты.
25. ![[Pasted image 20250415095653.png]]
26.  Оne-versus-all - учим к-й классификатор отличать к-й класс от всех остальных,  итоговый классификатор выдает класс, соответствующий самому уверенному из бинарных алгоритмов. 
27. Проблема данного подхода заключается в том, что каждый из классификаторов обучается на своей выборке, и значения линейных функций или, проще говоря, "выходы" классификаторов могут иметь разные масштабы. Из-за этого сравнивать их будет неправильно. 
28. Нормировать вектора весов, чтобы они выдавали ответы в одной и той же шкале, не всегда может быть разумным решением: так, в случае с SVM веса перестанут являться решением задачи, поскольку нормировка изменит норму весов.
29. All-versus-all - обучаем K(K-1)/2 классификаторов. Классификатор ij будем настраивать по подвыборке содержащей только объекты классов i и j.
30. Чтобы классифицировать новый объект, подадим его на вход каждого из построенных бинарных классификаторов. Каждый из них проголосует за своей класс; в качестве ответа выберем тот класс, за который наберется больше всего голосов.
31. Серый треугольник на стыке областей - это точки, для которых голоса разделились, для этих точек нет явного способа выдать обоснованное предсказание.
32. Калибровка вероятностей - некоторые алгоритмы не выдают корректные вероятности классов, в таком случае калибруют вероятности модели. В задаче бинарной классификации откалиброванным алгоритмом называют такой алгоритм, для которого доля положительных примеров (на основе реальных меток классов) для предсказаний в окрестности произвольной вероятности $p$ совпадает с этим значением $p$. Например, если взять объекты, для которых предсказанные вероятности близки к 0.7, то окажется, что среди них 70% принадлежат положительному классу.
33. Калибровка Платта: Пусть наш алгоритм выдаёт значения $f(x)$, итоговая вероятность ищется в виде $sigmoid(a*f(x)+b)$ с обучаемыми параметрами $a$, $b$. Эти параметры настраиваются методом максимума правдоподобия (минимизируя логистическую функцию потерь) на отложенной выборке или с помощью кросс валидации.
  
 

**Losses**
  1. MSE - то евклидово расстояние $|y - f_w(x)|_2$ между вектором таргетов и вектором ответов модели, то есть мы их приближаем в смысле самого простого и понятного «расстояния»,  с точки зрения статистики это соответствует гипотезе о том, что наши данные состоят из линейного «сигнала» и нормально распределенного «шума».
  2. Mean absolute error, абсолютная ошибка, появляется при замене нормы L2 в MSE на L1
  3. Mean absolute percentage error, часто используется в задачах прогнозирования, когда ответы могут быть различными по порядку величины, и при этом мы бы хотели верно угадать порядок, то есть мы не хотим штрафовать модель за предсказание 2000 вместо 1000 в разы сильней, чем за предсказание 2 вместо 1. $$MAPE(y, \widehat{y}) = \frac1N\sum_{i=1}^N \left|\frac{\widehat{y}_i-y_i}{y_i}\right|$$
  4. Симметрична версия MAPE(SMAPE): $$MAPE(y, \widehat{y}) = \frac1N\sum_{i=1}^N \left|\frac{\widehat{y}_i-y_i}{(|y_i|+|\widehat{y}_i|)/2}\right|$$
  5. Huber loss  - объединение MSE и MAE. Для прогнозов, близких к ответу, нам бы пригодились свойства гладкой квадратичной функции, а для плохих прогнозов важнее свойства абсолютного отклонения. У этой функции потерь есть параметр δ, который регулирует, что мы считаем  за выбросы. Если сделать этот параметр маленьким, то функция будет вести себя квадратично только в маленькой окрестности нуля.
  6. У функции потерь Хубера есть недостаток: её вторая производная имеет разрывы. Такого недостатка нет у функции потерь log-cosh: $L(y, a) = \log{\cosh{(y-a)}}$
