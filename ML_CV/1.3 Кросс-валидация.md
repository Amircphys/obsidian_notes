
![[Pasted image 20250510133000.png]]
Может показаться, что этот пример довольно искусственный, но он на самом деле легко переносится на модели любой сложности. Просто представьте себе, что часть обучаемых весов вашей сложной модели вам запретили обучать на трейне и вы начинаете так же, как и выше, оценивать их на тесте, то есть по факту **учить** на тесте.

А чем такая ситуация отличается от подбора _гиперпараметров_ модели (которые вы уже действительно не можете обучить на трейне) сразу на тестовом множестве? Вообще говоря, ничем.

### Стратификация (stratification)

При простом случайном разделении на тренировочное и тестовое множества (как в примерах выше) может случиться так, что их распределения окажутся не такими, как у всего исходного множества.

## k-Fold

Метод **k-Fold** чаще всего имеют в виду, когда говорят о кросс-валидации. Он является обобщением метода hold-out и представляет из себя следующий алгоритм:

1. Фиксируется некоторое целое число k (обычно от 5 до 10), меньшее числа семплов в датасете.
2. Датасет разбивается на k одинаковых частей (в последней части может быть меньше семплов, чем в остальных). Эти части называются _фолдами_.
3. Далее происходит k итераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли тренировочного. Модель учится на k−1 фолде и тестируется на оставшемся.
4. Финальный скор модели получается либо усреднением k получившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации.
Интересный вопрос состоит в том, какую модель брать для сравнения с остальными на отложенном тестовом множестве (если оно у вас есть) либо для окончательного применения в задаче. После применения k-Fold для одной модели у вас на руках останется k экземпляров (инстансов) этой модели, обученных на разных подмножествах трейна. Возможные варианты:

- делать предсказание с помощью усреднения предсказаний этих k инстансов;
- из этих k инстансов выбрать тот, который набрал лучший скор на своём тестовом фолде, и применять дальше его;
- заново обучить модель уже на всех k фолдах и делать предсказания уже этой моделью.

Выбирать, какой способ лучше, нужно в зависимости от конкретной задачи и имеющихся вычислительных возможностей.

### Stratified k-Fold

Метод **stratified k-Fold** — это метод k-Fold, использующий стратификацию при разбиении на фолды: каждый фолд содержит примерно такое же соотношение классов, как и всё исходное множество. Такой подход может потребоваться в случае, например, очень несбалансированного соотношения классов, когда при обычном random split некоторые фолды могут либо вообще не содержать семплов каких-то классов, либо содержать их слишком мало.

### Кросс-валидация на временных рядах

Существует такая задача, как прогнозирование временных рядов. На практике она часто возникает в форме «Что будет с показателями нашего продукта в ближайший день / месяц / год?»
![[Pasted image 20250510133443.png]]
### Примеры подмешивания тестовых данных в тренировочные
- вы проводили feature engineering на всём датасете, а не только на трейне. Например, вы строили [tf-idf](https://ru.wikipedia.org/wiki/TF-IDF) фичи или [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) на всех данных, а не только на трейне, тем самым заложив в свои тренировочные данные информацию о тестовых данных;
- вы применяли [стандартизацию](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) данных на всём датасете, а не только на трейне. Например, в случае [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) тестовое множество повлияет на используемые этим методом оценки среднего и стандартного отклонения;
- вы смешали трейн с тестом.
- Ваши данные зависят от времени, а вы при разбиении на трейн и тест это не учли. Например, вы применили обычный random split при работе с временными рядами, передав тем самым вашей модели информацию из будущего. Или вы предсказываете погоду на несколько часов вперёд, а у вас данные из одного и того же дня находятся и в трейне, и в тесте.
- У вас есть датасет с картинками, и вы решили увеличить количество семплов в нём с помощью [аугментаций](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=en) (примерами аугментаций могут служить симметричные отражения, повороты, растяжения). При этом вы взяли весь датасет, применили к нему аугментации и только после этого разделили на трейн и тест. В таком случае преобразования какой-то одной картинки могут попасть в оба множества, и вы получите пересечение трейна и теста.
- Вы решаете задачу рекомендации статей или постов пользователям на основании их комментариев и прочтений, при этом в трейне и тесте у вас одни и те же пользователи.
- Вы решаете какую-то задачу, где происходит работа с видеоданными. Например, распознаёте движение по видео или предсказываете фамилию актёра, попавшего в кадр. При этом в трейн и тест у вас попадают различные кадры из одного и того же видео.
- У вас есть спутниковые снимки, и вы хотите по ним предсказывать рельеф местности. При этом у вас в трейне и тесте есть кропы снимков над одними и теми же географическими координатами (хоть и в разное время).
- Вы обучаете голосового ассистента в звуковом потоке распознавать момент, когда к нему обращаются (например, «Слушай, Алиса», «Ok, Google»). При этом у вас в трейне и тесте одни и те же люди. Это, на первый взгляд, не очень страшная проблема, но на самом деле достаточно большая нейронка может запомнить интонации и манеру речи конкретного человека и будет использовать эти сведения для тестовых записей с этим человеком. При этом на новых людях распознавание будет работать сильно хуже.
- Вы хотите расширить тренировочный датасет какими-то дополнительными данными из другого датасета, но при этом оказывается, что другой датасет содержит в себе часть тестового множества вашего исходного датасета. Например, есть два публичных датасета: [ImageNet LSVRC 2015](https://academictorrents.com/collection/imagenet-lsvrc-2015), в котором 1000 классов и чуть больше миллиона изображений, и [ImageNet](http://image-net.org/), в котором 21 тысяча классов и чуть больше 14 миллионов изображений. При этом первый полностью содержится во втором, поэтому использование ImageNet для расширения обучающей выборки из ImageNet LSVRC 2015 может закончиться тем, что в трейне окажутся примеры из тестового множества, сформированного из ImageNet LSVRC 2015.