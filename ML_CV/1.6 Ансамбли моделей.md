
1. У вас есть несколько моделей, обученных на ваших данных.
2.  Можно ли придумать процедуру, которая позволит использовать все имеющиеся модели и при этом получить на тестовых данных качество выше, чем могла показать каждая из этих моделей в отдельности?
3.  $Q(a) = \mathbb{E}_x\mathbb{E}_{X,\epsilon}\left[y(x, \epsilon)-a(x, X)\right]^2$ где
	- X — обучающая выборка
	- x — точка из тестового множества
	- $y=f(x)+ϵ$ — целевая зависимость, которую мы можем измерить с точностью до случайного шума $ϵ$
	- a(x,X) — значение алгоритма, обученного на выборке X, в точке x
	- $E_x$​ — среднее по всем тестовым точкам и $E_{X,ϵ}$​ — среднее по всем обучающим выборкам X и случайному шуму ϵ
4.  Cуществует разложение на три компоненты — шум, смещение и разброс (bias-variance decomposition) $Q(a) = \mathbb{E}_x \text{bias}_X^2 a(x, X) + \mathbb{E}_x \mathbb{V}_X[a(x, X)] + \sigma^2,$
		![[Pasted image 20250513113807.png]]
5. Раз нам известно, что ошибка алгоритма раскладывается на шум, смещение и разброс, можно подумать над способом сократить ошибку. Будет разумно попытаться сначала уменьшить одну из составляющих. Понятно, что с шумом уже ничего не сделать — это минимально возможная ошибка. Какую можно придумать процедуру, чтобы, например, сократить разброс, не увеличивая смещение?
6. Идея **бэггинга**: Бутстрепом генерируем выборки и на каждом из них обучаем некую модель (базовая модель), затем в качестве предсказание для некоторого объекта берем среднее от предсказаний всех моделей. Конечная модель назвается ансамблем этих моделей 
7. Дисперсия композиции в $k$ раз меньше дисперсии отдельного алгоритма - **если базовые алгоритмы некоррелированы** ![[Pasted image 20250513114504.png]]
8. **Random Forest** - строгое выполнение этого предположения не обязательно, достаточно, чтобы алгоритмы были в некоторой степени не похожи друг на друга
9. Идея случайного леса - в процессе обучения каждого дерева в каждой вершине случайно выбираются n<N признаков, где N полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. 
10. Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации)
11. Random Forest (случайный лес) — комбинацию бэггинга и метода случайных подпространств над решающими деревьями.
12. На смещение бэггинг не влияет, а хочется, чтобы у леса оно было небольшим. Поэтому смещение должно быть небольшим у самих деревьев, из которых строится ансамбль.
13. У неглубоких деревьев - низкая дисперсия, высокое смещение
14. у глубоких деревьев нет проблем запомнить подвыборку подробно. Предсказание на тестовом объекте будет сильнее меняться в зависимости от обучающей подвыборки, зато в среднем будет близко к истине (высокая дисперсия, низкое смещение - Вывод: используем глубокие деревья.
15. Сколько признаков надо подавать дереву для обучения: практическая рекомендация — брать корень из числа всех признаков для классификации и треть признаков для регрессии.
16. Out-of-Bag: каждое дерево в случайном лесе обучается по подмножеству объектов, мы можем для каждого объекта $x_i$ найти деревья, которые были обучены без него, и вычислить по их ответам out-of-bag-ошибку
17. Беггинг - для базовых моделей низкое смещение, высокий разброс, цель - уменьшаем разброс
18. **Бустинг (boosting)**;  в бэггинге и случайном лесе базовые алгоритмы учатся независимо и параллельно, а в бустинге — последовательно
19. Каждый следующий базовый алгоритм в бустинге обучается так, чтобы уменьшить общую ошибку всех своих предшественников.
20. Поскольку основная цель бустинга — уменьшение смещения, в качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом.
21. Градиентный бустинг сейчас — основное продакшн-решение
22. **Стекинг (stacking)** - в качестве базовой модели используются разные модели, а не только из какого-то фиксированного семейства. 
23. результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения)
24.  - общая выборка разделяется на тренировочную и тестовую
     - тренировочная выборка делится на n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации
     - на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. 
     ![[Pasted image 20250513120649.png]]
     
25. С точки зрения смещения и разброса стекинг не имеет прямой интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, и, как следствие, её компоненты тоже будут убывать.