
# ClearML: –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É MLOps

  

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ –≤ ClearML](#–≤–≤–µ–¥–µ–Ω–∏–µ)

2. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ ClearML](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)

3. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞)

4. [–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã](#–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)

5. [–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã](#—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã)

6. [–†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏](#–¥–∞–Ω–Ω—ã–µ)

7. [–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏](#–º–æ–¥–µ–ª–∏)

8. [–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ –ø–∞–π–ø–ª–∞–π–Ω—ã](#–ø–∞–π–ø–ª–∞–π–Ω—ã)

9. [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã](#–ø—Ä–∏–º–µ—Ä—ã)

10. [–õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏](#–ø—Ä–∞–∫—Ç–∏–∫–∏)

  

## 1. –í–≤–µ–¥–µ–Ω–∏–µ –≤ ClearML {#–≤–≤–µ–¥–µ–Ω–∏–µ}

  

### –ß—Ç–æ —Ç–∞–∫–æ–µ ClearML?

  

ClearML (—Ä–∞–Ω–µ–µ Allegro Trains) ‚Äî —ç—Ç–æ open-source –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è MLOps, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–º–æ–≥–∞–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è–º –∏ –∏–Ω–∂–µ–Ω–µ—Ä–∞–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —É–ø—Ä–∞–≤–ª—è—Ç—å –≤—Å–µ–º –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º ML-–ø—Ä–æ–µ–∫—Ç–æ–≤. –≠—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è:

  

- **–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤** (experiment tracking)

- **–£–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏** (data management)

- **–í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π** (model versioning)

- **–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤** (pipeline orchestration)

- **–£–¥–∞–ª–µ–Ω–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á** (remote execution)

  

### –ó–∞—á–µ–º –Ω—É–∂–µ–Ω ClearML?

  

**–ü—Ä–æ–±–ª–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ—à–∞–µ—Ç ClearML:**

  

1. **–•–∞–æ—Å –≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö**: –ë–µ–∑ —Å–∏—Å—Ç–µ–º—ã –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ª–µ–≥–∫–æ –ø–æ—Ç–µ—Ä—è—Ç—å –≤–∞–∂–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

2. **–ù–µ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å**: –°–ª–æ–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —É—Å–ø–µ—à–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç

3. **–ü–æ—Ç–µ—Ä—è –¥–∞–Ω–Ω—ã—Ö**: –í–µ—Ä—Å–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π —Ç–µ—Ä—è—é—Ç—Å—è

4. **–ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤**: –†—É—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏

5. **–°–ª–æ–∂–Ω–æ—Å—Ç—å –¥–µ–ø–ª–æ—è**: –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –µ–¥–∏–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π

  

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ ClearML:**

  

- üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

- üîÑ –ü–æ–ª–Ω–∞—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

- üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤

- üóÑÔ∏è –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –¥–∞–Ω–Ω—ã—Ö

- üöÄ –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á

- üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ ML-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏

  

## 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ ClearML {#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞}

  

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

  

```

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

‚îÇ ClearML SDK ‚îÇ ‚îÇ ClearML Agent ‚îÇ ‚îÇ ClearML Server ‚îÇ

‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ

‚îÇ ‚Ä¢ Python API ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ ‚Ä¢ Task Runner ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ ‚Ä¢ Web UI ‚îÇ

‚îÇ ‚Ä¢ Auto-logging ‚îÇ ‚îÇ ‚Ä¢ Queue Manager ‚îÇ ‚îÇ ‚Ä¢ API Server ‚îÇ

‚îÇ ‚Ä¢ Data handling ‚îÇ ‚îÇ ‚Ä¢ Environment ‚îÇ ‚îÇ ‚Ä¢ File Server ‚îÇ

‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

```

  

**ClearML Server:**

- **Web UI**: –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

- **API Server**: REST API –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è

- **File Server**: –•—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π

  

**ClearML SDK:**

- Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –∫–æ–¥

- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏ –∏ –º–æ–¥–µ–ª—è–º–∏

  

**ClearML Agent:**

- –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –∑–∞–¥–∞—á –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –º–∞—à–∏–Ω–∞—Ö

- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥—è–º–∏ –∑–∞–¥–∞—á

- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

  

## 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ {#—É—Å—Ç–∞–Ω–æ–≤–∫–∞}

  

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ ClearML SDK

  

```bash

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞

pip install clearml

  

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏

pip install clearml[s3,gs,azure] # –¥–ª—è –æ–±–ª–∞—á–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â

```

  

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

  

```bash

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

clearml-init

```

  

–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω —Ñ–∞–π–ª `~/clearml.conf`:

  

```ini

api {

web_server: https://app.clear.ml

api_server: https://api.clear.ml

files_server: https://files.clear.ml

credentials {

"access_key": "YOUR_ACCESS_KEY"

"secret_key": "YOUR_SECRET_KEY"

}

}

```

  

### –õ–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ClearML Server (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

  

```bash

# –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Docker Compose

curl https://raw.githubusercontent.com/allegroai/clearml-server/master/docker/docker-compose.yml -o docker-compose.yml

docker-compose up -d

```

  

## 4. –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã {#–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã}

  

### Task (–ó–∞–¥–∞—á–∞)

  

Task ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ —Ä–∞–±–æ—Ç—ã –≤ ClearML. –ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∑–∞–¥–∞—á–µ–π.

  

```python

from clearml import Task

  

# –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏

task = Task.init(

project_name="My Project", # –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞

task_name="Experiment 1", # –ù–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

task_type="training" # –¢–∏–ø –∑–∞–¥–∞—á–∏

)

  

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–≥–µ—Ä–∞

logger = task.get_logger()

```

  

### Project (–ü—Ä–æ–µ–∫—Ç)

  

–ü—Ä–æ–µ–∫—Ç –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏. –°–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏.

  

```python

# –ü—Ä–æ–µ–∫—Ç—ã –º–æ–≥—É—Ç –∏–º–µ—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É

task = Task.init(

project_name="Computer Vision/Image Classification",

task_name="ResNet50 Training"

)

```

  

### Logger (–õ–æ–≥–≥–µ—Ä)

  

–õ–æ–≥–≥–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∑–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç–µ–∫—Å—Ç–∞ –∏ –¥—Ä—É–≥–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.

  

```python

logger = task.get_logger()

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∫–∞–ª—è—Ä–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫

logger.report_scalar("Loss", "Training", iteration=100, value=0.5)

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

logger.report_image("Samples", "Training Batch",

iteration=100, image=image_array)

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º

logger.report_histogram("Weights", "Layer1",

iteration=100, values=weights)

```

  

## 5. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã {#—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã}

  

### –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

  

```python

from clearml import Task

import numpy as np

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier

from sklearn.datasets import make_classification

from sklearn.metrics import accuracy_score, confusion_matrix

import seaborn as sns

  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏

task = Task.init(

project_name="ML Classification",

task_name="Random Forest Experiment",

tags=["sklearn", "classification", "random-forest"]

)

  

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–≥–µ—Ä–∞

logger = task.get_logger()

  

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

params = {

'n_estimators': 100,

'max_depth': 10,

'random_state': 42,

'n_samples': 1000,

'n_features': 20,

'n_classes': 3

}

  

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫ –∑–∞–¥–∞—á–µ

task.connect(params)

  

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

X, y = make_classification(

n_samples=params['n_samples'],

n_features=params['n_features'],

n_classes=params['n_classes'],

n_informative=15,

random_state=params['random_state']

)

  

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

X_train, X_test, y_train, y_test = train_test_split(

X, y, test_size=0.2, random_state=params['random_state']

)

  

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

model = RandomForestClassifier(

n_estimators=params['n_estimators'],

max_depth=params['max_depth'],

random_state=params['random_state']

)

  

print("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")

model.fit(X_train, y_train)

  

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫

logger.report_scalar("Metrics", "Accuracy", value=accuracy, iteration=0)

logger.report_scalar("Data", "Train Size", value=len(X_train), iteration=0)

logger.report_scalar("Data", "Test Size", value=len(X_test), iteration=0)

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ confusion matrix

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')

plt.title('Confusion Matrix')

plt.ylabel('True Label')

plt.xlabel('Predicted Label')

logger.report_matplotlib_figure("Confusion Matrix", "Test Set",

figure=plt.gcf(), iteration=0)

plt.close()

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

feature_importance = model.feature_importances_

plt.figure(figsize=(10, 6))

indices = np.argsort(feature_importance)[::-1][:10]

plt.bar(range(10), feature_importance[indices])

plt.title('Top 10 Feature Importances')

plt.xlabel('Feature Index')

plt.ylabel('Importance')

logger.report_matplotlib_figure("Feature Importance", "Top 10",

figure=plt.gcf(), iteration=0)

plt.close()

  

print(f"–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω! –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.4f}")

```

  

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤

  

#### –ü—Ä–∏–º–µ—Ä —Å PyTorch

  

```python

from clearml import Task

import torch

import torch.nn as nn

import torch.optim as optim

from torch.utils.data import DataLoader, TensorDataset

  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏

task = Task.init(project_name="Deep Learning", task_name="PyTorch CNN")

  

# ClearML –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç:

# - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏

# - –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞

# - –ó–Ω–∞—á–µ–Ω–∏—è loss –∏ –º–µ—Ç—Ä–∏–∫

# - –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

  

class SimpleCNN(nn.Module):

def __init__(self, num_classes=10):

super(SimpleCNN, self).__init__()

self.conv1 = nn.Conv2d(1, 32, 3, 1)

self.conv2 = nn.Conv2d(32, 64, 3, 1)

self.dropout1 = nn.Dropout2d(0.25)

self.dropout2 = nn.Dropout2d(0.5)

self.fc1 = nn.Linear(9216, 128)

self.fc2 = nn.Linear(128, num_classes)

  

def forward(self, x):

x = self.conv1(x)

x = torch.relu(x)

x = self.conv2(x)

x = torch.relu(x)

x = torch.max_pool2d(x, 2)

x = self.dropout1(x)

x = torch.flatten(x, 1)

x = self.fc1(x)

x = torch.relu(x)

x = self.dropout2(x)

x = self.fc2(x)

return torch.log_softmax(x, dim=1)

  

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

model = SimpleCNN()

optimizer = optim.Adam(model.parameters(), lr=0.001)

criterion = nn.NLLLoss()

  

# –§–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞

X = torch.randn(1000, 1, 28, 28)

y = torch.randint(0, 10, (1000,))

dataset = TensorDataset(X, y)

dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

  

# –û–±—É—á–µ–Ω–∏–µ

logger = task.get_logger()

for epoch in range(5):

running_loss = 0.0

correct = 0

total = 0

for batch_idx, (data, target) in enumerate(dataloader):

optimizer.zero_grad()

output = model(data)

loss = criterion(output, target)

loss.backward()

optimizer.step()

running_loss += loss.item()

_, predicted = torch.max(output.data, 1)

total += target.size(0)

correct += (predicted == target).sum().item()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ 10 –±–∞—Ç—á–µ–π

if batch_idx % 10 == 0:

iteration = epoch * len(dataloader) + batch_idx

logger.report_scalar("Loss", "Training",

iteration=iteration, value=loss.item())

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–æ—Ö–∏

epoch_loss = running_loss / len(dataloader)

epoch_acc = 100 * correct / total

logger.report_scalar("Loss", "Epoch", iteration=epoch, value=epoch_loss)

logger.report_scalar("Accuracy", "Epoch", iteration=epoch, value=epoch_acc)

print(f'Epoch {epoch+1}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc:.2f}%')

```

  

#### –ü—Ä–∏–º–µ—Ä —Å TensorFlow/Keras

  

```python

from clearml import Task

import tensorflow as tf

from tensorflow import keras

import numpy as np

  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏

task = Task.init(project_name="Deep Learning", task_name="TensorFlow MNIST")

  

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö MNIST

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

  

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞

x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0

x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0

y_train = keras.utils.to_categorical(y_train, 10)

y_test = keras.utils.to_categorical(y_test, 10)

  

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

model = keras.Sequential([

keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),

keras.layers.MaxPooling2D((2, 2)),

keras.layers.Conv2D(64, (3, 3), activation='relu'),

keras.layers.MaxPooling2D((2, 2)),

keras.layers.Conv2D(64, (3, 3), activation='relu'),

keras.layers.Flatten(),

keras.layers.Dense(64, activation='relu'),

keras.layers.Dense(10, activation='softmax')

])

  

# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏

model.compile(

optimizer='adam',

loss='categorical_crossentropy',

metrics=['accuracy']

)

  

# ClearML –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—Å—Ç –∫–æ–ª–±—ç–∫ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–±—ç–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

from clearml.binding.keras_bind import KerasModelLogger

  

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

history = model.fit(

x_train, y_train,

batch_size=128,

epochs=10,

validation_data=(x_test, y_test),

verbose=1

)

  

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

logger = task.get_logger()

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏

model_summary = []

model.summary(print_fn=lambda x: model_summary.append(x))

logger.report_text('\n'.join(model_summary), print_console=False)

  

# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏

test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)

logger.report_scalar("Final Metrics", "Test Loss", value=test_loss, iteration=0)

logger.report_scalar("Final Metrics", "Test Accuracy", value=test_accuracy, iteration=0)

  

print(f"Test accuracy: {test_accuracy:.4f}")

```

  

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

  

```python

from clearml import Task

  

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

def run_experiment(learning_rate, batch_size, epochs):

task = Task.init(

project_name="Hyperparameter Tuning",

task_name=f"LR-{learning_rate}_BS-{batch_size}_E-{epochs}"

)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

params = {

'learning_rate': learning_rate,

'batch_size': batch_size,

'epochs': epochs

}

task.connect(params)

logger = task.get_logger()

# –°–∏–º—É–ª—è—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è

for epoch in range(epochs):

# –°–∏–º—É–ª—è—Ü–∏—è –º–µ—Ç—Ä–∏–∫ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è)

train_loss = np.random.exponential(scale=1.0) * (0.9 ** epoch)

val_loss = train_loss * (1 + np.random.normal(0, 0.1))

val_accuracy = 1 - val_loss * 0.1 + np.random.normal(0, 0.02)

logger.report_scalar("Loss", "Training", iteration=epoch, value=train_loss)

logger.report_scalar("Loss", "Validation", iteration=epoch, value=val_loss)

logger.report_scalar("Accuracy", "Validation", iteration=epoch, value=val_accuracy)

return val_accuracy

  

# –ó–∞–ø—É—Å–∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

import numpy as np

  

learning_rates = [0.001, 0.01, 0.1]

batch_sizes = [32, 64, 128]

  

results = []

for lr in learning_rates:

for bs in batch_sizes:

final_accuracy = run_experiment(lr, bs, epochs=10)

results.append({

'lr': lr,

'batch_size': bs,

'final_accuracy': final_accuracy

})

  

# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

for result in sorted(results, key=lambda x: x['final_accuracy'], reverse=True):

print(f"LR: {result['lr']}, BS: {result['batch_size']}, "

f"Accuracy: {result['final_accuracy']:.4f}")

```

  

## 6. –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ {#–¥–∞–Ω–Ω—ã–µ}

  

### Dataset Management

  

ClearML –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ—â–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏:

  

```python

from clearml import Dataset

import pandas as pd

import numpy as np

from pathlib import Path

  

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

dataset = Dataset.create(

dataset_name="Customer Data v1.0",

dataset_project="Data Management",

description="Customer dataset with features and labels"

)

  

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

np.random.seed(42)

n_samples = 10000

  

data = {

'customer_id': range(1, n_samples + 1),

'age': np.random.randint(18, 80, n_samples),

'income': np.random.normal(50000, 15000, n_samples),

'spending_score': np.random.randint(1, 100, n_samples),

'years_customer': np.random.randint(0, 20, n_samples),

'purchased': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])

}

  

df = pd.DataFrame(data)

  

# –°–æ–∑–¥–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏

data_dir = Path("./dataset_example")

data_dir.mkdir(exist_ok=True)

  

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤

df.to_csv(data_dir / "customer_data.csv", index=False)

  

# –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

metadata = {

"version": "1.0",

"total_samples": len(df),

"features": list(df.columns[:-1]),

"target": "purchased",

"class_distribution": df['purchased'].value_counts().to_dict()

}

  

import json

with open(data_dir / "metadata.json", "w") as f:

json.dump(metadata, f, indent=2)

  

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç

dataset.add_files(path=str(data_dir))

  

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ

dataset.upload()

  

# –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞

dataset.finalize()

  

print(f"Dataset created with ID: {dataset.id}")

print(f"Dataset URL: {dataset.get_default_storage()}")

```

  

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

  

```python

from clearml import Dataset, Task

import pandas as pd

  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏

task = Task.init(project_name="Data Processing", task_name="Load Dataset Example")

  

# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ –∏–º–µ–Ω–∏ –∏ –ø—Ä–æ–µ–∫—Ç—É

dataset = Dataset.get(

dataset_name="Customer Data v1.0",

dataset_project="Data Management"

)

  

# –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –∫–æ–ø–∏–∏

local_dataset_path = dataset.get_local_copy()

print(f"Dataset downloaded to: {local_dataset_path}")

  

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö

data_file = Path(local_dataset_path) / "customer_data.csv"

df = pd.read_csv(data_file)

  

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

metadata_file = Path(local_dataset_path) / "metadata.json"

with open(metadata_file, 'r') as f:

metadata = json.load(f)

  

print(f"Dataset info:")

print(f"- Samples: {metadata['total_samples']}")

print(f"- Features: {metadata['features']}")

print(f"- Target: {metadata['target']}")

print(f"- Class distribution: {metadata['class_distribution']}")

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞—Ç–∞—Å–µ—Ç–µ

logger = task.get_logger()

logger.report_table("Dataset Info", "Metadata",

table_plot=pd.DataFrame([metadata]))

  

# –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

stats = df.describe()

logger.report_table("Dataset Stats", "Descriptive Statistics",

table_plot=stats)

```

  

### –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤

  

```python

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞

def create_dataset_version(parent_dataset_id, version_name, modifications):

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

parent_dataset = Dataset.get(dataset_id=parent_dataset_id)

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏

dataset = Dataset.create(

dataset_name=parent_dataset.name,

dataset_project=parent_dataset.project,

description=f"Updated version: {version_name}",

parent_datasets=[parent_dataset_id]

)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

parent_path = parent_dataset.get_local_copy()

df = pd.read_csv(Path(parent_path) / "customer_data.csv")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π

if 'remove_outliers' in modifications:

# –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ –¥–æ—Ö–æ–¥—É

q1 = df['income'].quantile(0.25)

q3 = df['income'].quantile(0.75)

iqr = q3 - q1

lower_bound = q1 - 1.5 * iqr

upper_bound = q3 + 1.5 * iqr

df = df[(df['income'] >= lower_bound) & (df['income'] <= upper_bound)]

if 'add_features' in modifications:

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

df['income_per_year'] = df['income'] / df['years_customer'].replace(0, 1)

df['age_group'] = pd.cut(df['age'], bins=[0, 30, 50, 100],

labels=['Young', 'Middle', 'Senior'])

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏

new_data_dir = Path("./dataset_v2")

new_data_dir.mkdir(exist_ok=True)

df.to_csv(new_data_dir / "customer_data.csv", index=False)

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

metadata = {

"version": version_name,

"parent_version": parent_dataset.name,

"total_samples": len(df),

"features": [col for col in df.columns if col != 'purchased'],

"target": "purchased",

"class_distribution": df['purchased'].value_counts().to_dict(),

"modifications": modifications

}

with open(new_data_dir / "metadata.json", "w") as f:

json.dump(metadata, f, indent=2)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –¥–∞—Ç–∞—Å–µ—Ç

dataset.add_files(path=str(new_data_dir))

dataset.upload()

dataset.finalize()

return dataset

  

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏

parent_id = "your_dataset_id_here" # ID –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

new_dataset = create_dataset_version(

parent_id,

"v2.0",

['remove_outliers', 'add_features']

)

  

print(f"New dataset version created: {new_dataset.id}")

```

  

## 7. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏ {#–º–æ–¥–µ–ª–∏}

  

### –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π

  

```python

from clearml import Task, OutputModel

import joblib

from sklearn.ensemble import RandomForestClassifier

from sklearn.datasets import make_classification

from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score

import numpy as np

  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏

task = Task.init(project_name="Model Management", task_name="Model Training and Saving")

  

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

  

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

model = RandomForestClassifier(n_estimators=100, random_state=42)

model.fit(X_train, y_train)

  

# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫

logger = task.get_logger()

logger.report_scalar("Performance", "Accuracy", value=accuracy, iteration=0)

  

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ

model_filename = "random_forest_model.pkl"

joblib.dump(model, model_filename)

  

# –°–æ–∑–¥–∞–Ω–∏–µ OutputModel –¥–ª—è ClearML

output_model = OutputModel(

task=task,

framework="scikit-learn",

name="Random Forest Classifier"

)

  

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏

output_model.set_model_metadata({

"accuracy": accuracy,

"n_features": X.shape[1],

"n_classes": len(np.unique(y)),

"model_type": "RandomForestClassifier",

"hyperparameters": {

"n_estimators": 100,

"random_state": 42

}

})

  

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏

output_model.update_weights(weights_filename=model_filename)

  

print(f"Model saved with accuracy: {accuracy:.4f}")

print(f"Model ID: {output_model.id}")

```

  

### –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

  

```python

from clearml import Task, InputModel

import joblib

import numpy as np

  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

task = Task.init(project_name="Model Management", task_name="Model Inference")

  

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ ID

model_id = "your_model_id_here" # ID –º–æ–¥–µ–ª–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞

input_model = InputModel(model_id=model_id)

  

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏

model_path = input_model.get_local_copy()

print(f"Model downloaded to: {model_path}")

  

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏

model = joblib.load(model_path)

  

# –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏

metadata = input_model.get_model_metadata()

print("Model metadata:")

for key, value in metadata.items():

print(f" {key}: {value}")

  

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

np.random.seed(123)

new_data = np.random.randn(5, 20) # 5 –æ–±—Ä–∞–∑—Ü–æ–≤ —Å 20 –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏

  

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

predictions = model.predict(new_data)

probabilities = model.predict_proba(new_data)

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

logger = task.get_logger()

  

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

import pandas as pd

results_df = pd.DataFrame({

'Sample': range(1, len(predictions) + 1),

'Prediction': predictions,

'Probability_Class_0': probabilities[:, 0],

'Probability_Class_1': probabilities[:, 1]

})

  

logger.report_table("Predictions", "Results", table_plot=results_df)

  

print("Predictions completed:")

print(results_df)

```

  

### Model Registry - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏—è–º–∏ –º–æ–¥–µ–ª–µ–π

  

```python

from clearml import Task, Model

import joblib

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

from sklearn.datasets import make_classification

from sklearn.model_selection import train_test_split, cross_val_score

from sklearn.metrics import accuracy_score

import numpy as np

  

def train_and_register_model(model_class, model_params, model_name, tags=None):

"""–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –µ—ë –≤ Model Registry"""

# –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏

task = Task.init(

project_name="Model Registry",

task_name=f"Training {model_name}",

tags=tags or []

)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

model = model_class(**model_params)

model.fit(X_train, y_train)

# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

# –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è

cv_scores = cross_val_score(model, X_train, y_train, cv=5)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫

logger = task.get_logger()

logger.report_scalar("Performance", "Test Accuracy", value=accuracy, iteration=0)

logger.report_scalar("Performance", "CV Mean", value=cv_scores.mean(), iteration=0)

logger.report_scalar("Performance", "CV Std", value=cv_scores.std(), iteration=0)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

model_filename = f"{model_name.lower().replace(' ', '_')}.pkl"

joblib.dump(model, model_filename)

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–µ—Å—Ç—Ä–µ

from clearml import OutputModel

output_model = OutputModel(

task=task,

framework="scikit-learn",

name=model_name

)

# –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏

metadata = {

"test_accuracy": float(accuracy),

"cv_mean_accuracy": float(cv_scores.mean()),

"cv_std_accuracy": float(cv_scores.std()),

"n_features": X.shape[1],

"n_samples_train": len(X_train),

"n_samples_test": len(X_test),

"model_params": model_params,

"model_class": model_class.__name__

}

output_model.set_model_metadata(metadata)

output_model.update_weights(weights_filename=model_filename)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–≥–æ–≤

if tags:

output_model.set_model_tags(tags)

return output_model, accuracy

  

# –û–±—É—á–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

models_to_train = [

{

'class': RandomForestClassifier,

'params': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42},

'name': 'Random Forest v1',

'tags': ['baseline', 'tree-based']

},

{

'class': RandomForestClassifier,

'params': {'n_estimators': 200, 'max_depth': 15, 'random_state': 42},

'name': 'Random Forest v2',

'tags': ['improved', 'tree-based']

},

{

'class': GradientBoostingClassifier,

'params': {'n_estimators': 100, 'learning_rate': 0.1, 'random_state': 42},

'name': 'Gradient Boosting v1',

'tags': ['boosting', 'tree-based']

}

]

  

# –û–±—É—á–µ–Ω–∏–µ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

model_results = []

for model_config in models_to_train:

print(f"Training {model_config['name']}...")

model, accuracy = train_and_register_model(

model_config['class'],

model_config['params'],

model_config['name'],

model_config['tags']

)

model_results.append({

'name': model_config['name'],

'model_id': model.id,

'accuracy': accuracy

})

print(f" Completed. Accuracy: {accuracy:.4f}, Model ID: {model.id}")

  

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

print("\nModel Comparison:")

print("-" * 50)

for result in sorted(model_results, key=lambda x: x['accuracy'], reverse=True):

print(f"{result['name']:<20} | Accuracy: {result['accuracy']:.4f} | ID: {result['model_id']}")

```

  

### –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Ä–∞–±–æ—Ç–∞ —Å Model Registry

  

```python

from clearml import Model

import pandas as pd

  

def compare_models_in_project(project_name):

"""–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–µ–∫—Ç–µ"""

# –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–æ–µ–∫—Ç–µ

models = Model.query_models(project_name=project_name)

model_data = []

for model in models:

metadata = model.get_model_metadata()

model_info = {

'name': model.name,

'id': model.id,

'created': model.created,

'framework': model.framework,

'tags': ', '.join(model.tags) if model.tags else '',

}

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

if metadata:

model_info.update({

key: value for key, value in metadata.items()

if isinstance(value, (int, float, str)) and len(str(value)) < 50

})

model_data.append(model_info)

# –°–æ–∑–¥–∞–Ω–∏–µ DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

df = pd.DataFrame(model_data)

return df

  

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π

comparison_df = compare_models_in_project("Model Registry")

print("Model Comparison:")

print(comparison_df.to_string(index=False))

  

# –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏

if 'test_accuracy' in comparison_df.columns:

best_model_row = comparison_df.loc[comparison_df['test_accuracy'].idxmax()]

print(f"\nBest model: {best_model_row['name']} (Accuracy: {best_model_row['test_accuracy']:.4f})")

# –ü–æ–º–µ—Ç–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º —Ç–µ–≥–æ–º

best_model = Model(model_id=best_model_row['id'])

current_tags = best_model.tags or []

if 'production-candidate' not in current_tags:

best_model.set_model_tags(current_tags + ['production-candidate'])

print("Model tagged as production candidate")

```

  

## 8. –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ –ø–∞–π–ø–ª–∞–π–Ω—ã {#–ø–∞–π–ø–ª–∞–π–Ω—ã}

  

### –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞

  

```python

from clearml import Task, Dataset

from clearml.automation import PipelineController

import pandas as pd

import numpy as np

from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score

import joblib

  

def create_ml_pipeline():

"""–°–æ–∑–¥–∞–µ—Ç –ø–∞–π–ø–ª–∞–π–Ω –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞

pipe = PipelineController(

name="ML Pipeline Example",

project="Pipelines",

version="1.0",

description="End-to-end ML pipeline: Data ‚Üí Train ‚Üí Evaluate"

)

# –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

pipe.add_step(

name="data_preparation",

base_task_project="Pipeline Steps",

base_task_name="Data Preparation Template",

parameter_override={

"General/dataset_size": 10000,

"General/test_size": 0.2,

"General/random_state": 42

}

)

# –®–∞–≥ 2: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

pipe.add_step(

name="model_training",

parents=["data_preparation"],

base_task_project="Pipeline Steps",

base_task_name="Model Training Template",

parameter_override={

"General/n_estimators": 100,

"General/max_depth": 10,

"General/random_state": 42

}

)

# –®–∞–≥ 3: –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏

pipe.add_step(

name="model_evaluation",

parents=["model_training"],

base_task_project="Pipeline Steps",

base_task_name="Model Evaluation Template",

parameter_override={

"General/threshold": 0.8

}

)

# –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞

pipe.start()

print("Pipeline started!")

print(f"Pipeline ID: {pipe.id}")

return pipe

  

# –°–æ–∑–¥–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞

  

def create_data_preparation_template():

"""–°–æ–∑–¥–∞–µ—Ç —à–∞–±–ª–æ–Ω –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""

task = Task.init(

project_name="Pipeline Steps",

task_name="Data Preparation Template"

)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

params = {

"dataset_size": 1000,

"test_size": 0.2,

"random_state": 42,

"n_features": 20,

"n_classes": 2

}

task.connect(params)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

from sklearn.datasets import make_classification

X, y = make_classification(

n_samples=params["dataset_size"],

n_features=params["n_features"],

n_classes=params["n_classes"],

random_state=params["random_state"]

)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

X_train, X_test, y_train, y_test = train_test_split(

X, y,

test_size=params["test_size"],

random_state=params["random_state"]

)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

np.save("X_train.npy", X_train)

np.save("X_test.npy", X_test)

np.save("y_train.npy", y_train)

np.save("y_test.npy", y_test)

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã

task.upload_artifact("X_train", artifact_object=X_train)

task.upload_artifact("X_test", artifact_object=X_test)

task.upload_artifact("y_train", artifact_object=y_train)

task.upload_artifact("y_test", artifact_object=y_test)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏

logger = task.get_logger()

logger.report_scalar("Data", "Train Size", value=len(X_train), iteration=0)

logger.report_scalar("Data", "Test Size", value=len(X_test), iteration=0)

logger.report_scalar("Data", "Features", value=X.shape[1], iteration=0)

print(f"Data prepared: {len(X_train)} train, {len(X_test)} test samples")

return task

  

def create_training_template():

"""–°–æ–∑–¥–∞–µ—Ç —à–∞–±–ª–æ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""

task = Task.init(

project_name="Pipeline Steps",

task_name="Model Training Template"

)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏

params = {

"n_estimators": 100,

"max_depth": 10,

"random_state": 42

}

task.connect(params)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —à–∞–≥–∞

# –í —Ä–µ–∞–ª—å–Ω–æ–º –ø–∞–π–ø–ª–∞–π–Ω–µ —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –ø–µ—Ä–µ–¥–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

parent_task = Task.get_task(task_id="data_preparation_task_id") # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ ID –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω

X_train = parent_task.artifacts["X_train"].get()

y_train = parent_task.artifacts["y_train"].get()

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

model = RandomForestClassifier(

n_estimators=params["n_estimators"],

max_depth=params["max_depth"],

random_state=params["random_state"]

)

model.fit(X_train, y_train)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

model_filename = "trained_model.pkl"

joblib.dump(model, model_filename)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç

task.upload_artifact("trained_model", artifact_object=model_filename)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏

logger = task.get_logger()

logger.report_scalar("Model", "N Estimators", value=params["n_estimators"], iteration=0)

logger.report_scalar("Model", "Max Depth", value=params["max_depth"], iteration=0)

print("Model training completed")

return task

  

def create_evaluation_template():

"""–°–æ–∑–¥–∞–µ—Ç —à–∞–±–ª–æ–Ω –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏"""

task = Task.init(

project_name="Pipeline Steps",

task_name="Model Evaluation Template"

)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ü–µ–Ω–∫–∏

params = {

"threshold": 0.8

}

task.connect(params)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤

data_task = Task.get_task(task_id="data_preparation_task_id")

model_task = Task.get_task(task_id="model_training_task_id")

X_test = data_task.artifacts["X_test"].get()

y_test = data_task.artifacts["y_test"].get()

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏

model_path = model_task.artifacts["trained_model"].get_local_copy()

model = joblib.load(model_path)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

logger = task.get_logger()

logger.report_scalar("Performance", "Accuracy", value=accuracy, iteration=0)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–∞

meets_threshold = accuracy >= params["threshold"]

logger.report_scalar("Validation", "Meets Threshold", value=int(meets_threshold), iteration=0)

if meets_threshold:

print(f"‚úÖ Model passed validation! Accuracy: {accuracy:.4f} >= {params['threshold']}")

# –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –¥–ª—è –¥–µ–ø–ª–æ—è –º–æ–¥–µ–ª–∏

else:

print(f"‚ùå Model failed validation. Accuracy: {accuracy:.4f} < {params['threshold']}")

return task

  

# –°–æ–∑–¥–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–æ–≤ (–≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–∏–Ω —Ä–∞–∑)

print("Creating pipeline templates...")

# create_data_preparation_template()

# create_training_template()

# create_evaluation_template()

  

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞

# pipeline = create_ml_pipeline()

```

  

### –£—Å–ª–æ–≤–Ω—ã–µ –ø–∞–π–ø–ª–∞–π–Ω—ã –∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ

  

```python

from clearml.automation import PipelineController

  

def create_advanced_pipeline():

"""–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å —É—Å–ª–æ–≤–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º"""

pipe = PipelineController(

name="Advanced ML Pipeline",

project="Advanced Pipelines",

version="2.0"

)

# –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

pipe.add_step(

name="data_preparation",

base_task_project="Pipeline Steps",

base_task_name="Data Preparation Template"

)

# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

models = [

{"name": "random_forest", "type": "RandomForest", "n_estimators": 100},

{"name": "gradient_boosting", "type": "GradientBoosting", "n_estimators": 100},

{"name": "svm", "type": "SVM", "C": 1.0}

]

model_steps = []

for model_config in models:

step_name = f"train_{model_config['name']}"

pipe.add_step(

name=step_name,

parents=["data_preparation"],

base_task_project="Pipeline Steps",

base_task_name="Multi Model Training Template",

parameter_override={

"General/model_type": model_config["type"],

**{f"General/{k}": v for k, v in model_config.items() if k != "name"}

}

)

model_steps.append(step_name)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

pipe.add_step(

name="model_comparison",

parents=model_steps,

base_task_project="Pipeline Steps",

base_task_name="Model Comparison Template"

)

# –£—Å–ª–æ–≤–Ω—ã–π –¥–µ–ø–ª–æ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏

pipe.add_step(

name="conditional_deploy",

parents=["model_comparison"],

base_task_project="Pipeline Steps",

base_task_name="Conditional Deploy Template",

parameter_override={

"General/min_accuracy_threshold": 0.85,

"General/deploy_environment": "staging"

}

)

# –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞

pipe.start()

return pipe

  

# –®–∞–±–ª–æ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

def create_multi_model_training_template():

"""–®–∞–±–ª–æ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π"""

task = Task.init(

project_name="Pipeline Steps",

task_name="Multi Model Training Template"

)

params = {

"model_type": "RandomForest",

"n_estimators": 100,

"max_depth": 10,

"C": 1.0, # –¥–ª—è SVM

"random_state": 42

}

task.connect(params)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

# (–í —Ä–µ–∞–ª—å–Ω–æ–º –ø–∞–π–ø–ª–∞–π–Ω–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞

if params["model_type"] == "RandomForest":

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(

n_estimators=params["n_estimators"],

max_depth=params["max_depth"],

random_state=params["random_state"]

)

elif params["model_type"] == "GradientBoosting":

from sklearn.ensemble import GradientBoostingClassifier

model = GradientBoostingClassifier(

n_estimators=params["n_estimators"],

random_state=params["random_state"]

)

elif params["model_type"] == "SVM":

from sklearn.svm import SVC

model = SVC(

C=params["C"],

probability=True,

random_state=params["random_state"]

)

else:

raise ValueError(f"Unknown model type: {params['model_type']}")

# –û–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

# (–∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è)

return task

```

  

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ –ø–∞–π–ø–ª–∞–π–Ω–∞—Ö

  

```python

from clearml.automation import PipelineController

import smtplib

from email.mime.text import MIMEText

  

def create_monitored_pipeline():

"""–ü–∞–π–ø–ª–∞–π–Ω —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏"""

pipe = PipelineController(

name="Monitored ML Pipeline",

project="Production Pipelines",

version="1.0"

)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ö—É–∫–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

def on_step_completed(pipeline_controller, node, parameters):

"""–ö–æ–ª–±—ç–∫ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —à–∞–≥–∞"""

print(f"Step '{node.name}' completed successfully")

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

if hasattr(node, 'executed_task'):

task = node.executed_task

logger = task.get_logger()

logger.report_scalar("Pipeline", "Step Duration",

value=task.get_runtime_properties().get('duration', 0),

iteration=0)

def on_step_failed(pipeline_controller, node, parameters):

"""–ö–æ–ª–±—ç–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ –≤ —à–∞–≥–µ"""

print(f"Step '{node.name}' failed!")

# –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è

send_notification(

subject=f"Pipeline Failed: {node.name}",

message=f"Step {node.name} in pipeline {pipeline_controller.name} failed."

)

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–ª–±—ç–∫–æ–≤

pipe.set_default_execution_queue("default")

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à–∞–≥–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞

pipe.add_step(

name="data_validation",

base_task_project="Pipeline Steps",

base_task_name="Data Validation Template"

)

pipe.add_step(

name="model_training",

parents=["data_validation"],

base_task_project="Pipeline Steps",

base_task_name="Robust Training Template"

)

pipe.add_step(

name="model_validation",

parents=["model_training"],

base_task_project="Pipeline Steps",

base_task_name="Model Validation Template"

)

pipe.add_step(

name="performance_monitoring",

parents=["model_validation"],

base_task_project="Pipeline Steps",

base_task_name="Performance Monitor Template"

)

return pipe

  

def send_notification(subject, message, recipients=None):

"""–û—Ç–ø—Ä–∞–≤–∫–∞ email —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"""

if recipients is None:

recipients = ["ml-team@company.com"]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ SMTP (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à–∏)

smtp_server = "smtp.company.com"

smtp_port = 587

smtp_username = "pipeline@company.com"

smtp_password = "password"

try:

msg = MIMEText(message)

msg['Subject'] = subject

msg['From'] = smtp_username

msg['To'] = ', '.join(recipients)

server = smtplib.SMTP(smtp_server, smtp_port)

server.starttls()

server.login(smtp_username, smtp_password)

server.send_message(msg)

server.quit()

print(f"Notification sent: {subject}")

except Exception as e:

print(f"Failed to send notification: {e}")

  

# –®–∞–±–ª–æ–Ω —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

def create_data_validation_template():

"""–®–∞–±–ª–æ–Ω –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""

task = Task.init(

project_name="Pipeline Steps",

task_name="Data Validation Template"

)

params = {

"min_samples": 1000,

"max_missing_ratio": 0.1,

"required_features": ["feature1", "feature2", "target"]

}

task.connect(params)

logger = task.get_logger()

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–∏–º–µ—Ä)

# data = load_data()

# –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

validation_results = {

"sample_count_ok": True, # len(data) >= params["min_samples"]

"missing_data_ok": True, # missing_ratio <= params["max_missing_ratio"]

"features_ok": True, # all required features present

}

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

for check, passed in validation_results.items():

logger.report_scalar("Data Validation", check, value=int(passed), iteration=0)

# –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏

all_passed = all(validation_results.values())

logger.report_scalar("Data Validation", "Overall", value=int(all_passed), iteration=0)

if not all_passed:

raise ValueError("Data validation failed!")

print("Data validation passed!")

return task

```

  

## 9. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã {#–ø—Ä–∏–º–µ—Ä—ã}

  

### –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä: Computer Vision –ø—Ä–æ–µ–∫—Ç

  

```python

from clearml import Task, Dataset, Logger

import torch

import torch.nn as nn

import torch.optim as optim

from torch.utils.data import DataLoader

import torchvision

import torchvision.transforms as transforms

import matplotlib.pyplot as plt

import numpy as np

from sklearn.metrics import classification_report, confusion_matrix

import seaborn as sns

  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞

task = Task.init(

project_name="Computer Vision Project",

task_name="CIFAR-10 Classification with CNN",

tags=["computer-vision", "cnn", "cifar10", "pytorch"]

)

  

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

config = {

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞–Ω–Ω—ã—Ö

'batch_size': 128,

'num_workers': 4,

'download_data': True,

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏

'num_classes': 10,

'dropout_rate': 0.5,

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

'learning_rate': 0.001,

'momentum': 0.9,

'weight_decay': 1e-4,

'epochs': 20,

# –î—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

'device': 'cuda' if torch.cuda.is_available() else 'cpu',

'save_every': 5,

'log_every': 100

}

  

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫ –∑–∞–¥–∞—á–µ

task.connect(config)

logger = task.get_logger()

  

# –ö–ª–∞—Å—Å—ã CIFAR-10

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

  

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö

transform_train = transforms.Compose([

transforms.RandomCrop(32, padding=4),

transforms.RandomHorizontalFlip(),

transforms.ToTensor(),

transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),

])

  

transform_test = transforms.Compose([

transforms.ToTensor(),

transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),

])

  

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö

print("Loading CIFAR-10 dataset...")

trainset = torchvision.datasets.CIFAR10(

root='./data', train=True, download=config['download_data'], transform=transform_train

)

trainloader = DataLoader(

trainset, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers']

)

  

testset = torchvision.datasets.CIFAR10(

root='./data', train=False, download=config['download_data'], transform=transform_test

)

testloader = DataLoader(

testset, batch_size=config['batch_size'], shuffle=False, num_workers=config['num_workers']

)

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö

logger.report_scalar("Dataset", "Train Size", value=len(trainset), iteration=0)

logger.report_scalar("Dataset", "Test Size", value=len(testset), iteration=0)

logger.report_scalar("Dataset", "Num Classes", value=config['num_classes'], iteration=0)

  

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö

def show_sample_images():

dataiter = iter(trainloader)

images, labels = next(dataiter)

# –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

def denormalize(tensor):

mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)

std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)

return tensor * std + mean

fig, axes = plt.subplots(2, 8, figsize=(15, 4))

axes = axes.ravel()

for idx in range(16):

img = denormalize(images[idx])

img = torch.clamp(img, 0, 1)

axes[idx].imshow(np.transpose(img.numpy(), (1, 2, 0)))

axes[idx].set_title(f'{classes[labels[idx]]}')

axes[idx].axis('off')

plt.tight_layout()

logger.report_matplotlib_figure("Data Samples", "Training Examples", figure=fig, iteration=0)

plt.close()

  

show_sample_images()

  

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ CNN

class CIFAR10CNN(nn.Module):

def __init__(self, num_classes=10, dropout_rate=0.5):

super(CIFAR10CNN, self).__init__()

# –ü–µ—Ä–≤—ã–π –±–ª–æ–∫ —Å–≤–µ—Ä—Ç–∫–∏

self.conv1 = nn.Conv2d(3, 32, 3, padding=1)

self.bn1 = nn.BatchNorm2d(32)

self.conv2 = nn.Conv2d(32, 32, 3, padding=1)

self.bn2 = nn.BatchNorm2d(32)

self.pool1 = nn.MaxPool2d(2, 2)

self.dropout1 = nn.Dropout2d(0.25)

# –í—Ç–æ—Ä–æ–π –±–ª–æ–∫ —Å–≤–µ—Ä—Ç–∫–∏

self.conv3 = nn.Conv2d(32, 64, 3, padding=1)

self.bn3 = nn.BatchNorm2d(64)

self.conv4 = nn.Conv2d(64, 64, 3, padding=1)

self.bn4 = nn.BatchNorm2d(64)

self.pool2 = nn.MaxPool2d(2, 2)

self.dropout2 = nn.Dropout2d(0.25)

# –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫ —Å–≤–µ—Ä—Ç–∫–∏

self.conv5 = nn.Conv2d(64, 128, 3, padding=1)

self.bn5 = nn.BatchNorm2d(128)

self.conv6 = nn.Conv2d(128, 128, 3, padding=1)

self.bn6 = nn.BatchNorm2d(128)

self.pool3 = nn.MaxPool2d(2, 2)

self.dropout3 = nn.Dropout2d(0.25)

# –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏

self.fc1 = nn.Linear(128 * 4 * 4, 512)

self.dropout4 = nn.Dropout(dropout_rate)

self.fc2 = nn.Linear(512, num_classes)

def forward(self, x):

# –ü–µ—Ä–≤—ã–π –±–ª–æ–∫

x = torch.relu(self.bn1(self.conv1(x)))

x = torch.relu(self.bn2(self.conv2(x)))

x = self.pool1(x)

x = self.dropout1(x)

# –í—Ç–æ—Ä–æ–π –±–ª–æ–∫

x = torch.relu(self.bn3(self.conv3(x)))

x = torch.relu(self.bn4(self.conv4(x)))

x = self.pool2(x)

x = self.dropout2(x)

# –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫

x = torch.relu(self.bn5(self.conv5(x)))

x = torch.relu(self.bn6(self.conv6(x)))

x = self.pool3(x)

x = self.dropout3(x)

# –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏

x = x.view(-1, 128 * 4 * 4)

x = torch.relu(self.fc1(x))

x = self.dropout4(x)

x = self.fc2(x)

return x

  

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

device = torch.device(config['device'])

model = CIFAR10CNN(num_classes=config['num_classes'], dropout_rate=config['dropout_rate'])

model.to(device)

  

# –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏

total_params = sum(p.numel() for p in model.parameters())

trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

  

logger.report_scalar("Model", "Total Parameters", value=total_params, iteration=0)

logger.report_scalar("Model", "Trainable Parameters", value=trainable_params, iteration=0)

  

print(f"Model created with {trainable_params:,} trainable parameters")

  

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞

criterion = nn.CrossEntropyLoss()

optimizer = optim.SGD(

model.parameters(),

lr=config['learning_rate'],

momentum=config['momentum'],

weight_decay=config['weight_decay']

)

  

# –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ–±—É—á–µ–Ω–∏—è

scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

  

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏

def evaluate_model(model, dataloader, criterion, device):

model.eval()

total_loss = 0.0

correct = 0

total = 0

all_predictions = []

all_labels = []

with torch.no_grad():

for data, target in dataloader:

data, target = data.to(device), target.to(device)

output = model(data)

loss = criterion(output, target)

total_loss += loss.item()

_, predicted = torch.max(output.data, 1)

total += target.size(0)

correct += (predicted == target).sum().item()

all_predictions.extend(predicted.cpu().numpy())

all_labels.extend(target.cpu().numpy())

avg_loss = total_loss / len(dataloader)

accuracy = 100 * correct / total

return avg_loss, accuracy, all_predictions, all_labels

  

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

print("Starting training...")

best_accuracy = 0.0

train_losses = []

train_accuracies = []

val_losses = []

val_accuracies = []

  

for epoch in range(config['epochs']):

model.train()

running_loss = 0.0

correct = 0

total = 0

for batch_idx, (data, target) in enumerate(trainloader):

data, target = data.to(device), target.to(device)

optimizer.zero_grad()

output = model(data)

loss = criterion(output, target)

loss.backward()

optimizer.step()

running_loss += loss.item()

_, predicted = torch.max(output.data, 1)

total += target.size(0)

correct += (predicted == target).sum().item()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ N –±–∞—Ç—á–µ–π

if batch_idx % config['log_every'] == 0:

iteration = epoch * len(trainloader) + batch_idx

logger.report_scalar("Loss", "Training Batch", iteration=iteration, value=loss.item())

current_acc = 100 * correct / total if total > 0 else 0

logger.report_scalar("Accuracy", "Training Batch", iteration=iteration, value=current_acc)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–ø–æ—Ö–∏

epoch_train_loss = running_loss / len(trainloader)

epoch_train_acc = 100 * correct / total

# –í–∞–ª–∏–¥–∞—Ü–∏—è

val_loss, val_acc, _, _ = evaluate_model(model, testloader, criterion, device)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫

train_losses.append(epoch_train_loss)

train_accuracies.append(epoch_train_acc)

val_losses.append(val_loss)

val_accuracies.append(val_acc)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–æ—Ö–∏

logger.report_scalar("Loss", "Training Epoch", iteration=epoch, value=epoch_train_loss)

logger.report_scalar("Loss", "Validation Epoch", iteration=epoch, value=val_loss)

logger.report_scalar("Accuracy", "Training Epoch", iteration=epoch, value=epoch_train_acc)

logger.report_scalar("Accuracy", "Validation Epoch", iteration=epoch, value=val_acc)

logger.report_scalar("Learning Rate", "Current", iteration=epoch, value=optimizer.param_groups[0]['lr'])

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏

if val_acc > best_accuracy:

best_accuracy = val_acc

torch.save(model.state_dict(), 'best_model.pth')

logger.report_scalar("Best", "Validation Accuracy", iteration=epoch, value=best_accuracy)

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞

scheduler.step()

print(f'Epoch {epoch+1}/{config["epochs"]}: '

f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, '

f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')

  

# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

print("Final evaluation...")

model.load_state_dict(torch.load('best_model.pth'))

final_loss, final_acc, predictions, true_labels = evaluate_model(model, testloader, criterion, device)

  

logger.report_scalar("Final", "Test Loss", value=final_loss, iteration=0)

logger.report_scalar("Final", "Test Accuracy", value=final_acc, iteration=0)

  

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫

cm = confusion_matrix(true_labels, predictions)

plt.figure(figsize=(10, 8))

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',

xticklabels=classes, yticklabels=classes)

plt.title('Confusion Matrix')

plt.ylabel('True Label')

plt.xlabel('Predicted Label')

logger.report_matplotlib_figure("Results", "Confusion Matrix", figure=plt.gcf(), iteration=0)

plt.close()

  

# –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

classification_rep = classification_report(true_labels, predictions,

target_names=classes, output_dict=True)

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º

for class_name in classes:

if class_name in classification_rep:

metrics = classification_rep[class_name]

logger.report_scalar(f"Class Metrics/{class_name}", "Precision",

value=metrics['precision'], iteration=0)

logger.report_scalar(f"Class Metrics/{class_name}", "Recall",

value=metrics['recall'], iteration=0)

logger.report_scalar(f"Class Metrics/{class_name}", "F1-Score",

value=metrics['f1-score'], iteration=0)

  

# –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è

fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

  

# –ü–æ—Ç–µ—Ä–∏

ax1.plot(train_losses, label='Training Loss', color='blue')

ax1.plot(val_losses, label='Validation Loss', color='red')

ax1.set_title('Loss over Epochs')

ax1.set_xlabel('Epoch')

ax1.set_ylabel('Loss')

ax1.legend()

ax1.grid(True)

  

# –¢–æ—á–Ω–æ—Å—Ç—å

ax2.plot(train_accuracies, label='Training Accuracy', color='blue')

ax2.plot(val_accuracies, label='Validation Accuracy', color='red')

ax2.set_title('Accuracy over Epochs')

ax2.set_xlabel('Epoch')

ax2.set_ylabel('Accuracy (%)')

ax2.legend()

ax2.grid(True)

  

# –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º

class_accuracies = []

for class_idx, class_name in enumerate(classes):

class_mask = np.array(true_labels) == class_idx

if np.sum(class_mask) > 0:

class_acc = np.mean(np.array(predictions)[class_mask] == class_idx) * 100

class_accuracies.append(class_acc)

else:

class_accuracies.append(0)

  

ax3.bar(classes, class_accuracies, color='skyblue')

ax3.set_title('Accuracy by Class')

ax3.set_xlabel('Class')

ax3.set_ylabel('Accuracy (%)')

ax3.tick_params(axis='x', rotation=45)

  

# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

ax4.hist(predictions, bins=len(classes), alpha=0.7, label='Predictions', color='lightcoral')

ax4.hist(true_labels, bins=len(classes), alpha=0.7, label='True Labels', color='lightblue')

ax4.set_title('Distribution of Predictions vs True Labels')

ax4.set_xlabel('Class')

ax4.set_ylabel('Count')

ax4.legend()

  

plt.tight_layout()

logger.report_matplotlib_figure("Training", "Complete Analysis", figure=fig, iteration=0)

plt.close()

  

print(f"\nTraining completed!")

print(f"Best validation accuracy: {best_accuracy:.2f}%")

print(f"Final test accuracy: {final_acc:.2f}%")

  

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏

task.upload_artifact('final_model', artifact_object='best_model.pth')

print("Model and artifacts uploaded to ClearML!")

```

  

### –ü—Ä–∏–º–µ—Ä: NLP –ø—Ä–æ–µ–∫—Ç —Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞–º–∏

  

```python

from clearml import Task

import torch

from transformers import (

AutoTokenizer, AutoModelForSequenceClassification,

TrainingArguments, Trainer, DataCollatorWithPadding

)

from datasets import Dataset

import pandas as pd

import numpy as np

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

import matplotlib.pyplot as plt

import seaborn as sns

  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏

task = Task.init(

project_name="NLP Projects",

task_name="Sentiment Analysis with BERT",

tags=["nlp", "transformers", "bert", "sentiment-analysis"]

)

  

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

config = {

'model_name': 'bert-base-uncased',

'num_labels': 3, # –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π

'max_length': 512,

'batch_size': 16,

'learning_rate': 2e-5,

'num_epochs': 3,

'warmup_steps': 500,

'weight_decay': 0.01,

'seed': 42

}

  

task.connect(config)

logger = task.get_logger()

  

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

torch.manual_seed(config['seed'])

np.random.seed(config['seed'])

  

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞

def create_sample_data():

"""–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""

positive_texts = [

"I love this product! It's amazing!",

"Great service and excellent quality.",

"Highly recommended, fantastic experience!",

"Best purchase I've made this year.",

"Outstanding customer support and fast delivery."

] * 200

negative_texts = [

"Terrible product, waste of money.",

"Poor quality and bad customer service.",

"I regret buying this, very disappointed.",

"Completely useless, doesn't work at all.",

"Worst experience ever, avoid at all costs."

] * 200

neutral_texts = [

"The product is okay, nothing special.",

"Average quality, meets basic expectations.",

"It's fine, does what it's supposed to do.",

"Decent product for the price.",

"Neither good nor bad, just average."

] * 200

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

texts = positive_texts + negative_texts + neutral_texts

labels = [2] * len(positive_texts) + [0] * len(negative_texts) + [1] * len(neutral_texts)

# –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ

data = list(zip(texts, labels))

np.random.shuffle(data)

texts, labels = zip(*data)

return list(texts), list(labels)

  

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

texts, labels = create_sample_data()

  

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation/test

train_size = int(0.7 * len(texts))

val_size = int(0.15 * len(texts))

  

train_texts = texts[:train_size]

train_labels = labels[:train_size]

val_texts = texts[train_size:train_size + val_size]

val_labels = labels[train_size:train_size + val_size]

test_texts = texts[train_size + val_size:]

test_labels = labels[train_size + val_size:]

  

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö

logger.report_scalar("Dataset", "Train Size", value=len(train_texts), iteration=0)

logger.report_scalar("Dataset", "Validation Size", value=len(val_texts), iteration=0)

logger.report_scalar("Dataset", "Test Size", value=len(test_texts), iteration=0)

  

# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤

label_names = ['Negative', 'Neutral', 'Positive']

train_label_counts = pd.Series(train_labels).value_counts().sort_index()

  

plt.figure(figsize=(10, 6))

plt.subplot(1, 2, 1)

plt.bar(label_names, train_label_counts.values, color=['red',