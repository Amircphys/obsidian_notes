
**Цели:** 
	 1. Снизить количество людей, которые видят спам до 1 % 
	 2. Снизить количество людей, которые не возвращают большие кредиты (более 1 млн рублей до 0.05% от всех, кому вы выдаем  такие.
	 3. Повысить среднее время пользования нашим сервисом до 100 минут в день.
 
 Цели должны быть
	 1. **конкретными (Specific)**
	 2. **измеримым (Measurable)**
	 3. **достижимыми(Attainalble)**
	 4. **релевантными (releavant)**
	 5. **ограниченными по времени (time based)**

Итоги:
	1. Не делаем то, что делать не надо
	2. Используем SMART для формулировки целей
	3. Думаем об измерении бизнес метрик


**Зачем нам данные?**
1. Учим на них модели
2. Ищем в них инсайты
3. Делаем по ним предсказания
4. Оцениваем по ним результат

Data Store - данные должны где-то храниться - hdfs, PostgreSQL, S3, Google Cloud Storage

1. Какие релевантные датасеты доступны? - может быть, такое что один и тот же датасет используется несколько раз, и каждый раз его получают написав какой-нибудь скрипт. Тогда лучше его сохранить в store, чтобы и другие сотрудники быстро смогли получить их
2. Достаточно ли точны и надежны данные?  - На сколько можно доверять данным
3. Как получить доступ к этим данным? - В зависимости от позиции, могуть дать или не дать доступ к данным.
4. Какие фичи можно получить при джойне?
5. Часто ли обновляются данные?
6. Можно ли будет получать эти фичи в realtime?

Feature Store - абстакция над хранилищем данных, которая позволяет извлекать дынные как для обучения так и для инференса. 


Итоги:
1. Данные храним и структурируем=)
2. Стремимся уметь отвечать на вышеизложенные вопросы


Классическая разработка модели (MLOPS Level 0) - получаем данные, извлекаем нужные признаки (после ресерча) и обучаем модель, далее отдает тем людям которые развертывают модель:
![[Pasted image 20241022145236.png]]

Минусы данного подхода:
	- разные люди отвечают за обучение и инференс, те кто разварачивают модель часто будут обращаться к тем кто обучал модель;
	- Те кто обучает модель, слабо представляют как модель будет работать в продакшене, где-то может быть узкое горлышко и тд
	- Мы забываем какую последовательность действий надо сделать, чтобы получить модель
	- Мы не можем переобучить модель - нужно все с нуля начинать (можно забыть процесс обучения, может сотрудник, отвечающий за обучение модели  уволился и тд)
	- Потери данных или кода
	- Потери знаний о том, как обучать и выкатывать

Минусы связанные с  выкаткой в прод:
	● Наши данные не такие, как на проде
	● Фичи получаются не тем же способом, что на проде
	● DS не думает о том, что на проде
	● Теряется способ воспроизвести модель


MLOPS Level 1 - DS делает пайплайны, которые делают модели
![[Pasted image 20241022150311.png]]



Мы берем данные из store где хранятся наши данные, проводим эксперименты - обучаем модели и получаем рабочую версию модели. Далее мы весь код отправляем в git - извлечение данных, получения фичей и обучения модели, чтобы все можно было запустить одной командой в продакшн окружении и на выходе получить модель и отчет о том что было сделано. Далее модель попадает в Model registry - сущность, где хранятся версии моделей, это может быть папка на сервере, на s3  и тд. Далее запускаются скрипты, которые написаны для запуска модели в пайплайн и они используют только что добавленную версию модели. Скрипты может запуститьсам DS. 

Что поможет это реализовать?
	- **git** (Версионирование  кода)
	- **DVC** (Версионирование  данных)
	- **Apache Airflow** (Шедулинг и оркестрация)
	- **mlflow, clearML** (Трекинг экспериментов)

Итоги:
	1. Нужно писать переиспользуемый, версионируемый, тестируемый код
	2. Нужно осознание того, что модель — это не цель


**Deploy Models**
1. **Пакетный паттерн** (batch task [ссылка]( https://github.com/mercari/ml-system-design-pattern/blob/master/Serving-patterns/Batch-pattern/design_en.md)). 
		Есть сущность joba (например скрипт на питоне), которая может выплеснуть новую версию модели, если ей отдать на вход данные. Как только накопятся данные (например раз в неделю, месяц и тд). 
		Когда нужно использовать?
			- Если вам НЕ нужно получать результат прогноза в реальном времени или почти в реальном времени.
			- Для массивной обработки данных
			- Когда для корректной работы продакшена достаточно
			запускать PREDICTION по расписанию(раз в сутки, в час, в 10
			минут)
		Что поможет реализовать? - **Apache Airflow**
		
2. **Синхронный паттерн** - юзер хочет ответ сразу (Загружаешь фотку - получаешь ответ) [ссылка](https://github.com/mercari/ml-system-design-pattern/blob/master/Serving-patterns/Synchronous-pattern/design_en.md) 
		ПЛЮСЫ:
			1. Просто в реализации
			2. Как правило, низкое latency
		МИНУСЫ:
			1. Скорость предсказания будет бутылочным горлышком производительности вашей системы
			2. Если предсказание слишком долгое, то нужно сделать так, чтобы пользователь этого не замечал
		
		Что поможет реализовать?
			- Fast Api
			- Docker
			- Nginx
3. **Асинхронный(near realtime) паттерн** - когда вам не нужен результат прямо сейчас (Удаление спам сообщений в Instagram), [ссылка]( https://github.com/mercari/ml-system-design-pattern/blob/master/Serving-patterns/Asynchronous-pattern/design_en.md)
		Плюсы:
			- Можно отделить бизнес логику и логику предсказания;
			- Более высокая(по сравнению с синхронным) пропускная способность;
			- Вы не заблокированы временем предсказания;
		Минусы:
			- Как правило, не подходит для использования в реальном времени.
			- Нужны очереди/кеши, etc
		Что поможет реализовать - Apache Kafka, RabbitMQ
Итоги:
1. Есть несколько сценариев использования ML моделей
2. Нужно уметь выбирать нужный в зависимости от ограничений, целей
3. Реализуются по разному

Куда деплоить? - Kebernettes, Google Cloud, hadoop, на устройства

**Embedded** - Использование модели встроено в приложение:
	- Нет сетевой задержки
	- Можно запустить на девайсе
	- Сложно масштабировать независимо от приложения

**Model as a service** - Использование модели вынесено в отдельный  сервис

	- Сетевой задержка
	- Независимый релизный цикл
	- Можно масштабировать независимо от приложения

**Мониторинг** - Что поможет реализовать? - Graphana

**MLOPS: level 2** - добавляется CI/CD 
![[Pasted image 20241022163312.png]]

**За что отвечает Data Scientist/ML Engineer:**
	- Разработку модели
	- За то, что модель готова к эксплуатации
	- Развертывание модели +-
	- Оценка качества модели онлайн-оффлайн
	- Итеративное улучшение моделей

**За что отвечает Data Engineer:**
	- Создание платформы данных
	- Разработку конкретных источников для моделей
	- Оптимизацию производительности data pipelines

**За что отвечает Software Engineer:**
	- Встраивание моделек в продукт


**За что отвечает DEVOPS**:
     - Создание платформы для развертывания и мониторинга приложений ( в том числе и моделей)
     - Создание CICD пайплайнов для компонентов  ML систем


Итоги:
1. Люди всякие нужны, люди всякие важны
2. Data Scientist должен иметь возможность доставлять результаты своего труда САМ
3. Переписывать за DS код тренировки/инференса моделей — антипаттерн